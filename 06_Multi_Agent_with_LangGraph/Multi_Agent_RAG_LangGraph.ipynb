{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxpWDFG11o3G"
      },
      "source": [
        "# Multi-Agent Workflows + RAG - LangGraph\n",
        "\n",
        "Today we'll be looking at an example of a Multi-Agent workflow that's powered by LangGraph, LCEL, and more!\n",
        "\n",
        "We're going to be, more specifically, looking at a \"heirarchical agent teams\" from the [AutoGen: Enabling Next-Gen LLM\n",
        "Applications via Multi-Agent Conversation](https://arxiv.org/pdf/2308.08155) paper.\n",
        "\n",
        "This will be the final \"graph\" of our system:\n",
        "\n",
        "![image](https://i.imgur.com/Bhc7RVE.png)\n",
        "\n",
        "It's important to keep in mind that the actual implementation will be constructed of 3 separate graphs, the final one having 2 graphs as nodes! LangGraph is a heckuva tool!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyzoBrWoYeOZ"
      },
      "source": [
        "# 🤝 BREAKOUT ROOM #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx3oaVoX5cA2"
      },
      "source": [
        "## Dependencies\n",
        "\n",
        "We'll start, as we normally do, by grabbing our dependencies.\n",
        "\n",
        "We'll be using LangChain and LangGraph to power our application, so let's start by grabbing those!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs6HUTgecbzW",
        "outputId": "c2f4d9e5-56ea-4173-f3ff-9ab3cc28a7ca"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langgraph==0.2.14 langchain==0.2.14 langchain_openai==0.1.23 langchain_core==0.2.35 langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMzWFUc25oqT"
      },
      "source": [
        "We're going to be showing a simple RAG chain as part of our LangGraph - and so we'll need specific dependencies for that as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qEUBCOdukjwc"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU --disable-pip-version-check qdrant-client pymupdf tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpv2MWqu5vS9"
      },
      "source": [
        "Since we'll be relying on OpenAI's suite of models to power our agents today, we'll want to provide our OpenAI API Key.\n",
        "\n",
        "We're also going to be using the Tavily search tool - so we'll want to provide that API key as well!\n",
        "\n",
        "Instruction for how to obtain the Tavily API key can be found:\n",
        "\n",
        "1. [Tavily API Key](https://app.tavily.com/sign-in)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h30OjkLfeR2Y",
        "outputId": "f75bb26e-b89d-4611-c29b-f339b3e868af"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_LD7rwT6PbO"
      },
      "source": [
        "## Task 1: Simple LCEL RAG\n",
        "\n",
        "Now that we have our dependencies set-up - let's create a simple RAG chain that works over a single PDF.\n",
        "\n",
        "> NOTE: While this particular example is very straight forward - you can \"plug in\" any complexity of chain you desire as a node in a LangGraph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY7T5kxJ6jGn"
      },
      "source": [
        "## Retrieval\n",
        "\n",
        "The 'R' in 'RAG' - this is, at this point, fairly straightforward!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGuPxSCk7Ztz"
      },
      "source": [
        "#### Data Collection and Processing\n",
        "\n",
        "A classic first step, at this point, let's grab our desired document!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LfuoEYRCln3H"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "\n",
        "docs = PyMuPDFLoader(\"https://arxiv.org/pdf/2404.19553\").load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://arxiv.org/pdf/2404.19553', 'file_path': 'https://arxiv.org/pdf/2404.19553', 'page': 0, 'total_pages': 5, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240501003931Z', 'modDate': 'D:20240501003931Z', 'trapped': ''}, page_content='Extending Llama-3’s Context Ten-Fold Overnight\\nPeitian Zhang1,2, Ninglu Shao1,2, Zheng Liu1∗, Shitao Xiao1, Hongjin Qian1,2,\\nQiwei Ye1, Zhicheng Dou2\\n1 Beijing Academy of Artificial Intelligence\\n2 Gaoling School of Artificial Intelligence, Renmin University of China\\nnamespace.pt@gmail.com\\nzhengliu1026@gmail.com\\nAbstract\\nWe extend the context length of Llama-3-8B-Instruct from 8K to 80K via QLoRA\\nfine-tuning2. The entire training cycle is super efficient, which takes 8 hours on one\\n8xA800 (80G) GPU machine. The resulted model exhibits superior performances\\nacross a broad range of evaluation tasks, such as NIHS, topic retrieval, and long-\\ncontext language understanding; meanwhile, it also well preserves the original\\ncapability over short contexts. The dramatic context extension is mainly attributed\\nto merely 3.5K synthetic training samples generated by GPT-4 , which indicates\\nthe LLMs’ inherent (yet largely underestimated) potential to extend its original\\ncontext length. In fact, the context length could be extended far beyond 80K\\nwith more computation resources. Therefore, the team will publicly release the\\nentire resources (including data, model, data generation pipeline, training code) so\\nas to facilitate the future research from the community: https://github.com/\\nFlagOpen/FlagEmbedding.\\n1\\nIntroduction\\nRecently, considerable attention has been directed towards long-context large language models,\\nwhere different approaches are adopted to establish long-context capabilities for large language\\nmodels [4, 14, 5, 8, 9, 16, 2]. However, most of them require significant compute and resources to\\naccomplish.\\nIn this technical report, we propose an efficient solution for entitling the long-context capabilities for\\nLLMs, with which we extend the context length of Llama-3-8B-Instruct3 from 8K to 80K. Specifically,\\nwe use GPT-4 [13] to synthesize 3.5K long-context training data, covering three long-context tasks:\\n1. Single-Detail QA: the inquiry targets on one specific detail in a long context. To construct\\ndata for this task, we slice out a short segment (e.g., a chunk with less than 4096 tokens)\\nfrom a long context (e.g., a book or a long paper) and prompt GPT-4 to generate multiple\\nquestion-answer pairs based on this segment.\\n2. Multi-Detail QA: the inquiry requires information aggregation and reasoning over multiple\\ndetails in a long context. We define two types of long context. The homogeneous\\ncontext contains a coherent text, such as a book or a long paper. We prompt GPT-4 to\\ngenerate multiple question-answer pairs that require aggregating and analyzing information\\nfrom different locations in the context. The heterogeneous context consists of multiple\\nindependent texts. Notably, we perform clustering over a large corpus then extract texts from\\n∗Corresponding author.\\n2The model is noted as Llama-3-8B-Instruct-80K-QLoRA given its max context length during fine-tuning.\\nHowever, users could apply the model for even longer contexts via extrapolation.\\n3https://llama.meta.com/llama3/\\nPreprint. Under review.\\narXiv:2404.19553v1  [cs.CL]  30 Apr 2024\\n'),\n",
              " Document(metadata={'source': 'https://arxiv.org/pdf/2404.19553', 'file_path': 'https://arxiv.org/pdf/2404.19553', 'page': 1, 'total_pages': 5, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240501003931Z', 'modDate': 'D:20240501003931Z', 'trapped': ''}, page_content='8000\\n14315\\n20631\\n26947\\n33263\\n39578\\n45894\\n52210\\n58526\\n64842\\n71157\\n77473\\n83789\\n90105\\n96421\\n102736\\n109052\\n115368\\n121684\\n128000\\nContext Length\\n0\\n11\\n22\\n33\\n44\\n55\\n66\\n77\\n88\\n100\\nDepth Percent\\n1.0\\nNeedle In A HayStack\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\nAccuracy Score from GPT3.5\\nFigure 1: The accuracy score of Llama-3-8B-Instruct-80K-QLoRA on Needle-In-A-HayStack task.\\nThe blue vertical line indicates the training length, i.e. 80K.\\nthe same cluster to form each heterogeneous context. Therefore, the grouped texts share\\nsome semantic similarity. We then prompt GPT-4 to ask about the similarities/dissimilarities\\nacross these texts.\\n3. Biography Summarization: we prompt GPT-4 to write a biography for each main character\\nin a given book.\\nFor all three tasks, the length of context is between 64K to 80K. Note that longer data can also be\\nsynthesized following the same methodology. When training, we organize the question-answer pairs\\nfor the same context in one multi-turn conversation then fine-tune the LLM to correctly answer the\\nquestions given the entire long context as input. Following previous work4, we mix 5K instances\\nrandomly chosen from RedPajama [6] to mitigate forgetting. We also mix LongAlpaca [5] in the\\ntraining set, which contains 12K instruction tuning instances with 16K length at maximum. Therefore,\\nthe entire training dataset contains 20K instances.\\nWe use QLoRA [7] to efficiently fine-tune the model. We apply LoRA on all Q,K,V,O projections\\nand additionally train the embedding layer. We set LoRA rank to 32 and alpha to 16. The learning\\nrate is 5e-5 with linear decay and no warmups. The batch size is 8. Gradient checkpointing is enabled.\\nNo parallel strategy is required thanks to the efficient implementation from Unsloth [1]. We train the\\nmodel for 1 epoch, which takes 8 hours to complete on a 8xA800 (80G) machine. Importantly, we\\nexpand the RoPE base from 500K to 200M in training.\\nOur contributions are highlighted as follows:\\n• We release Llama-3-8B-Instruct-80K-QLoRA, which extends the context length of Llama-\\n3-8B-Instruct from 8K to 80K. The entire resources including the model, training data, and\\ncode are all publicly available, which may advance the field of training long-context LLMs.\\n• Our training recipe is simple and efficient, while the resulted model demonstrates remark-\\nable performance on downstream long-context tasks. Further research can be made to\\nimprove our approach.\\n2\\nExperiments\\nWe evaluate our model on popular long-context benchmarks, then compare it with the original\\nLlama-3-8B-Instruct model and the long-context Llama-3-8B-Instruct-262K from the community5.\\n4https://www.together.ai/blog/llama-2-7b-32k\\n5https://huggingface.co/gradientai/Llama-3-8B-Instruct-262k\\n2\\n'),\n",
              " Document(metadata={'source': 'https://arxiv.org/pdf/2404.19553', 'file_path': 'https://arxiv.org/pdf/2404.19553', 'page': 2, 'total_pages': 5, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240501003931Z', 'modDate': 'D:20240501003931Z', 'trapped': ''}, page_content='3K\\n6K\\n9K\\n11K\\n14K\\n16K\\n21K\\n26K\\n31K\\n36K\\nContext Length\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nAccuracy\\nLlama-3-8B-Instruct\\nLlama-3-8B-Instruct-262k\\nLlama-3-8B-Instruct-80K-QLoRA\\nFigure 2: The accuracy of Topic Retrieval task.\\nModel\\nSingle-Doc\\nMulti-Doc\\nSumm.\\nFew-Shot\\nSynthetic\\nCode\\nAvg\\nLlama-3-8B-Instruct\\n37.33\\n36.04\\n26.83\\n69.56\\n37.75\\n53.24\\n43.20\\nLlama-3-8B-Instruct-262K\\n37.29\\n31.20\\n26.18\\n67.25\\n44.25\\n62.71\\n43.73\\nLlama-3-8B-Instruct-80K-QLoRA\\n43.57\\n43.07\\n28.93\\n69.15\\n48.50\\n51.95\\n47.19\\nTable 1: Evaluation results on LongBench. For Llama-3-8B-Instruct, we use 8K context length.\\nModel\\nLongBookQA Eng\\nLongBookSum Eng\\nGPT-4\\n22.22\\n14.73\\nLlama-3-8B-Instruct\\n7.00\\n16.40\\nLlama-3-8B-Instruct-262K\\n20.30\\n10.34\\nLlama-3-8B-Instruct-80K-QLoRA\\n30.92\\n14.73\\nTable 2: Evaluation results on InfBench. For Llama-3-8B-Instruct, we use 8K context length. The\\nresults of GPT-4 is copied from the paper [17].\\nModel\\nSTEM\\nSocial\\nHumanities\\nOthers\\nAvg\\nLlama-2-7B-Chat\\n35.92\\n54.37\\n51.74\\n51.42\\n47.22\\nMistral-7B-v0.2-Instruct\\n48.79\\n69.95\\n64.99\\n61.64\\n60.10\\nLlama-3-8B-Instruct\\n53.87\\n75.66\\n69.44\\n69.75\\n65.91\\nLlama-3-8B-Instruct-262K\\n52.10\\n73.26\\n67.15\\n69.80\\n64.34\\nLlama-3-8B-Instruct-80K-QLoRA\\n53.10\\n73.24\\n67.32\\n68.79\\n64.44\\nTable 3: Zero-shot performance on MMLU.\\nFirstly, we leverage the Needle-In-A-Haystack task, which aims to recall an irrelevant piece of\\ninformation (a.k.a. needle) inserted into a lengthy context (a.k.a. haystack). The accuracy is evaluated\\nwith GPT3.5. We use the same needle and haystack as in the official repository6. Our model achieves\\n100% accuracy over all its training context length. Besides, the model generalizes well to the unseen\\npositions (80K∼128K).\\nSecondly, we report the Topic Retrieval [12] accuracy in Figure 2. This task synthesizes a long\\nconversation with multiple independent discussions of a certain topic between the user and the\\nassistant. Then the LLM is required to repeat the first topic as is in the conversation. We use the\\nconversations made up of [5,10,15,20,25,30,40,50,60,70] topics for evaluation. It can be observed\\nthat Llama-3-8B-Instruct fails to remember the topic when the context is longer than 9K. However,\\nthe accuracy of our model remains 100% throughout all context lengths.\\n6https://github.com/gkamradt/LLMTest_NeedleInAHaystack\\n3\\n'),\n",
              " Document(metadata={'source': 'https://arxiv.org/pdf/2404.19553', 'file_path': 'https://arxiv.org/pdf/2404.19553', 'page': 3, 'total_pages': 5, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240501003931Z', 'modDate': 'D:20240501003931Z', 'trapped': ''}, page_content='Thirdly, we evaluate our model on LongBench [3], which contains a variety of real-world long-context\\ntasks. Most context on this benchmark is shorter than 32K. Thus, we use 32K context length by\\ndefault and 8K for Llama-3-8B-Instruct. The results are shown in Table 1. Our model significantly\\nand consistently outperforms all baselines except on the code completion task. Mixing more code\\ndata in training may mitigate this problem.\\nForthly, we employ the English Long-Book QA and the Long-Book Summarization task from\\nInfiniteBench [17] to assess the model’s performance on really long context. The testing instances are\\nusually longer than 100K. We truncate them to 80K. According to Table 2, Llama-3-8B-Instruct-80K-\\nQLoRA excels on answering the questions based on the long context. It also achieves competitive\\nperformance against GPT-4 in terms of summarization. Interestingly, Llama-3-8B-Instruct with\\n8K context outperforms GPT-4 with 128K context on summarization. This is likely to be a metric-\\noriented issue (currently rouge-f1 is used) since the summary may have different paraphrases, which\\nmay not necessarily overlap with the ground truth.\\nLastly, in Table 3, we compare the zero-shot performance of our model and the baselines on\\nMMLU [10] benchmark. We also include Llama-2-7B-Chat [15] and Mistral-7B-Instruct-v0.2 [11]\\nfor comparison. It can be observed that both long-context models underperform the original Llama-3-\\n8B-Instruct, indicating that context extension may compromise the model’s short-context capability.\\nThis observation is in line with previous research [14]. However, our model’s performance is still\\nsuperior to other open-source models at the same scale.\\nReferences\\n[1] Unsloth.ai. https://github.com/unslothai/unsloth, 2023.\\n[2] S. An, Z. Ma, Z. Lin, N. Zheng, and J.-G. Lou. Make your llm fully utilize the context, 2024.\\n[3] Y. Bai, X. Lv, J. Zhang, H. Lyu, J. Tang, Z. Huang, Z. Du, X. Liu, A. Zeng, L. Hou, Y. Dong,\\nJ. Tang, and J. Li. Longbench: A bilingual, multitask benchmark for long context understanding,\\n2023.\\n[4] S. Chen, S. Wong, L. Chen, and Y. Tian. Extending context window of large language models\\nvia positional interpolation, 2023.\\n[5] Y. Chen, S. Qian, H. Tang, X. Lai, Z. Liu, S. Han, and J. Jia. Longlora: Efficient fine-tuning of\\nlong-context large language models, 2024.\\n[6] T. Computer. Redpajama: An open source recipe to reproduce llama training dataset, 2023.\\n[7] T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettlemoyer. Qlora: Efficient finetuning of\\nquantized llms, 2023.\\n[8] Y. Ding, L. L. Zhang, C. Zhang, Y. Xu, N. Shang, J. Xu, F. Yang, and M. Yang. Longrope:\\nExtending llm context window beyond 2 million tokens, 2024.\\n[9] Y. Fu, R. Panda, X. Niu, X. Yue, H. Hajishirzi, Y. Kim, and H. Peng. Data engineering for\\nscaling language models to 128k context, 2024.\\n[10] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Measuring\\nmassive multitask language understanding, 2021.\\n[11] A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. de las Casas, F. Bressand,\\nG. Lengyel, G. Lample, L. Saulnier, L. R. Lavaud, M.-A. Lachaux, P. Stock, T. L. Scao, T. Lavril,\\nT. Wang, T. Lacroix, and W. E. Sayed. Mistral 7b, 2023.\\n[12] D. Li*, R. Shao*, A. Xie, Y. Sheng, L. Zheng, J. E. Gonzalez, I. Stoica, X. Ma, , and H. Zhang.\\nHow long can open-source llms truly promise on context length?, June 2023.\\n[13] OpenAI. Gpt-4 technical report, 2024.\\n[14] B. Peng, J. Quesnelle, H. Fan, and E. Shippole. Yarn: Efficient context window extension of\\nlarge language models, 2023.\\n[15] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra,\\nP. Bhargava, S. Bhosale, D. Bikel, L. Blecher, C. C. Ferrer, M. Chen, G. Cucurull, D. Esiobu,\\nJ. Fernandes, J. Fu, W. Fu, B. Fuller, C. Gao, V. Goswami, N. Goyal, A. Hartshorn, S. Hosseini,\\nR. Hou, H. Inan, M. Kardas, V. Kerkez, M. Khabsa, I. Kloumann, A. Korenev, P. S. Koura, M.-A.\\nLachaux, T. Lavril, J. Lee, D. Liskovich, Y. Lu, Y. Mao, X. Martinet, T. Mihaylov, P. Mishra,\\n4\\n'),\n",
              " Document(metadata={'source': 'https://arxiv.org/pdf/2404.19553', 'file_path': 'https://arxiv.org/pdf/2404.19553', 'page': 4, 'total_pages': 5, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240501003931Z', 'modDate': 'D:20240501003931Z', 'trapped': ''}, page_content='I. Molybog, Y. Nie, A. Poulton, J. Reizenstein, R. Rungta, K. Saladi, A. Schelten, R. Silva, E. M.\\nSmith, R. Subramanian, X. E. Tan, B. Tang, R. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. Yan,\\nI. Zarov, Y. Zhang, A. Fan, M. Kambadur, S. Narang, A. Rodriguez, R. Stojnic, S. Edunov, and\\nT. Scialom. Llama 2: Open foundation and fine-tuned chat models, 2023.\\n[16] P. Zhang, Z. Liu, S. Xiao, N. Shao, Q. Ye, and Z. Dou. Soaring from 4k to 400k: Extending\\nllm’s context with activation beacon, 2024.\\n[17] X. Zhang, Y. Chen, S. Hu, Z. Xu, J. Chen, M. K. Hao, X. Han, Z. L. Thai, S. Wang, Z. Liu, and\\nM. Sun. ∞bench: Extending long context evaluation beyond 100k tokens, 2024.\\n5\\n')]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_t_F1zG6vXa"
      },
      "source": [
        "Now we can chunk it down to size!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5R7A_z8CgL79"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def tiktoken_len(text):\n",
        "    tokens = tiktoken.encoding_for_model(\"gpt-4o-mini\").encode(\n",
        "        text,\n",
        "    )\n",
        "    return len(tokens)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 300,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = tiktoken_len,\n",
        ")\n",
        "\n",
        "split_chunks = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "740"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tiktoken.encoding_for_model(\"gpt-4o-mini\").encode(docs[0].page_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Extending Llama-3’s Context Ten-Fold Overnight\\nPeitian Zhang1,2, Ninglu Shao1,2, Zheng Liu1∗, Shitao Xiao1, Hongjin Qian1,2,\\nQiwei Ye1, Zhicheng Dou2\\n1 Beijing Academy of Artificial Intelligence\\n2 Gaoling School of Artificial Intelligence, Renmin University of China\\nnamespace.pt@gmail.com\\nzhengliu1026@gmail.com\\nAbstract\\nWe extend the context length of Llama-3-8B-Instruct from 8K to 80K via QLoRA\\nfine-tuning2. The entire training cycle is super efficient, which takes 8 hours on one\\n8xA800 (80G) GPU machine. The resulted model exhibits superior performances\\nacross a broad range of evaluation tasks, such as NIHS, topic retrieval, and long-\\ncontext language understanding; meanwhile, it also well preserves the original\\ncapability over short contexts. The dramatic context extension is mainly attributed\\nto merely 3.5K synthetic training samples generated by GPT-4 , which indicates\\nthe LLMs’ inherent (yet largely underestimated) potential to extend its original\\ncontext length. In fact, the context length could be extended far beyond 80K\\nwith more computation resources. Therefore, the team will publicly release the\\nentire resources (including data, model, data generation pipeline, training code) so\\nas to facilitate the future research from the community: https://github.com/\\nFlagOpen/FlagEmbedding.\\n1\\nIntroduction\\nRecently, considerable attention has been directed towards long-context large language models,\\nwhere different approaches are adopted to establish long-context capabilities for large language\\nmodels [4, 14, 5, 8, 9, 16, 2]. However, most of them require significant compute and resources to\\naccomplish.\\nIn this technical report, we propose an efficient solution for entitling the long-context capabilities for\\nLLMs, with which we extend the context length of Llama-3-8B-Instruct3 from 8K to 80K. Specifically,\\nwe use GPT-4 [13] to synthesize 3.5K long-context training data, covering three long-context tasks:\\n1. Single-Detail QA: the inquiry targets on one specific detail in a long context. To construct\\ndata for this task, we slice out a short segment (e.g., a chunk with less than 4096 tokens)\\nfrom a long context (e.g., a book or a long paper) and prompt GPT-4 to generate multiple\\nquestion-answer pairs based on this segment.\\n2. Multi-Detail QA: the inquiry requires information aggregation and reasoning over multiple\\ndetails in a long context. We define two types of long context. The homogeneous\\ncontext contains a coherent text, such as a book or a long paper. We prompt GPT-4 to\\ngenerate multiple question-answer pairs that require aggregating and analyzing information\\nfrom different locations in the context. The heterogeneous context consists of multiple\\nindependent texts. Notably, we perform clustering over a large corpus then extract texts from\\n∗Corresponding author.\\n2The model is noted as Llama-3-8B-Instruct-80K-QLoRA given its max context length during fine-tuning.\\nHowever, users could apply the model for even longer contexts via extrapolation.\\n3https://llama.meta.com/llama3/\\nPreprint. Under review.\\narXiv:2404.19553v1  [cs.CL]  30 Apr 2024\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGE-VuMc7AKv"
      },
      "source": [
        "Now we've successfully split our single PDF into..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgYBHsdWmLvW",
        "outputId": "aa9a830e-f7db-4bb3-f542-c0614cb01aca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(split_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxaKmmyh7DHD"
      },
      "source": [
        "documents!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGWs7KTd7QPS"
      },
      "source": [
        "#### Embedding Model and Vector Store\n",
        "\n",
        "Now that we have our chunked document - lets create a vector store, which will first require us to create an embedding model to get the vector representations of our text!\n",
        "\n",
        "We'll use OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) model - as it's cheap, and performant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xLIWMMZCmfrj"
      },
      "outputs": [],
      "source": [
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTEi7Ww573sc"
      },
      "source": [
        "Now we can create our QDrant backed vector store!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Xct51f8omVAU"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "qdrant_vectorstore = Qdrant.from_documents(\n",
        "    split_chunks,\n",
        "    embedding_model,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"extending_context_window_llama_3\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzGq6o4s79Ar"
      },
      "source": [
        "Let's make sure we can access it as a retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OTnQZbWymi4K"
      },
      "outputs": [],
      "source": [
        "qdrant_retriever = qdrant_vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU8qSrMS7_D7"
      },
      "source": [
        "### Augmented\n",
        "\n",
        "Now that we have our retrieval process set-up, we need to set up our \"augmentation\" process - AKA a prompt template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lezTN0zCmk46"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUERY:\n",
        "{question}\n",
        "\n",
        "You are a helpful assistant. Use the available context to answer the question. If you can't answer the question, say you don't know.\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9fa63nM7IKK"
      },
      "source": [
        "### Generation\n",
        "\n",
        "Last, but certainly not least, let's put the 'G' in 'RAG' by adding our generator - in this case, we can rely on OpenAI's [`gpt-4o-mini`](https://platform.openai.com/docs/models/gpt-4o-mini) model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AwEi29-Jo3a8"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "openai_chat_model = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO-ZC0T98XJJ"
      },
      "source": [
        "### RAG - Retrieval Augmented Generation\n",
        "\n",
        "All that's left to do is combine our R, A, and G into a single chain - and we're off!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nlOJrPm_oT3S"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | qdrant_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | rag_prompt | openai_chat_model | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiWrbXpu8ggz"
      },
      "source": [
        "Let's test this out and make sure it works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "gJhFlW32pBPe",
        "outputId": "7aee04b6-608f-4639-adca-66225d4d3002"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the context of 'long context' as discussed in the document, 'context' refers to the amount of text or data that a large language model (LLM) can process at one time. Specifically, it pertains to the length of the input text that the model can analyze and understand, which can include extensive documents like books or detailed papers. The document mentions extending the context length of the Llama-3-8B-Instruct model from 8K tokens to 80K tokens, allowing it to handle much larger segments of text for tasks such as question answering and summarization.\""
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke({\"question\" : \"What does the 'context' in 'long context' refer to?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gReMizYk8qd-"
      },
      "source": [
        "### RAG Limitation\n",
        "\n",
        "Notice how we're hard-coding our data, while this is simply meant to be an illustrative example - you could easily extend this to work with any provied paper or document in order to have a more dynamic system.\n",
        "\n",
        "For now, we'll stick with this single hard-coded example in order to keep complexity down in an already very long notebook!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxkbuir-H5rE"
      },
      "source": [
        "##### 🏗️ Activity #1 (Bonus Marks)\n",
        "\n",
        "Allow the system to dynamically fetch Arxiv papers instead of hard coding them.\n",
        "\n",
        "> HINT: Tuesday's assignment will be very useful here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# uv add \"arxiv==2.1.3\"\n",
        "# uv sync"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the context of the provided summaries, \"long context\" refers to the length of text or data that a language model (like Llama-3) can process or understand at one time. Specifically, it pertains to the model's ability to handle larger amounts of input data, which in this case has been extended from 8,000 tokens to 80,000 tokens. This extension allows the model to maintain coherence and relevance over longer passages of text, enabling it to perform better in tasks that require understanding and generating language over extended contexts, such as long-context language understanding, topic retrieval, and other evaluation tasks. \n",
            "\n",
            "The ability to extend the context length is significant because it enhances the model's performance in scenarios where information is spread out over longer texts, which is common in many real-world applications.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "\n",
        "tool_belt = [\n",
        "    ArxivQueryRun(),\n",
        "]\n",
        "#----------------------------\n",
        "openai_chat_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "openai_chat_model_with_arxiv_tool = openai_chat_model.bind_tools(tool_belt)\n",
        "\n",
        "def retrieve_from_arxiv(query):\n",
        "    # Initialize the ArXiv tool\n",
        "    arxiv_tool = ArxivQueryRun()\n",
        "    \n",
        "    # Run the query\n",
        "    results = arxiv_tool.invoke(query)\n",
        "    \n",
        "    # Format the results as context\n",
        "    return {\"context\": results}\n",
        "\n",
        "# Update your prompt template\n",
        "RAG_PROMPT_with_tool = \"\"\"\n",
        "You are a helpful assistant with access to research papers from ArXiv.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUERY:\n",
        "{question}\n",
        "\n",
        "Using the context provided, answer the query. If you need more information, you can use the arxiv tool to search for additional papers.\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt_with_tool = ChatPromptTemplate.from_template(RAG_PROMPT_with_tool)\n",
        "\n",
        "# Build your RAG chain\n",
        "rag_chain_with_tool = (\n",
        "    RunnablePassthrough.assign(\n",
        "        context=lambda x: retrieve_from_arxiv(f\"Extending Llama-3's Context Ten-Fold Overnight\")\n",
        "    )\n",
        "    | rag_prompt_with_tool\n",
        "    | openai_chat_model_with_arxiv_tool\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Run your chain\n",
        "response = rag_chain_with_tool.invoke({\"question\": \"What does the 'context' in 'long context' refer to?\"})\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U6a_pqQ9uWf"
      },
      "source": [
        "## Task 2: Helper Functions for Agent Graphs\n",
        "\n",
        "We'll be using a number of agents, nodes, and supervisors in the rest of the notebook - and so it will help to have a collection of useful helper functions that we can leverage to make our lives easier going forward.\n",
        "\n",
        "Let's start with the most simple one!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDUnpEEl-L_F"
      },
      "source": [
        "#### Import Wall\n",
        "\n",
        "Here's a wall of imports we'll be needing going forward!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "TbzoL3Q3-SG1"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Callable, List, Optional, TypedDict, Union\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain_core.tools import BaseTool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langgraph.graph import END, StateGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb6Z3EEz-Asi"
      },
      "source": [
        "### Agent Node Helper\n",
        "\n",
        "Since we're going to be wrapping each of our agents into a node - it will help to have an easy way to create the node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5IF7KWfS-JKd"
      },
      "outputs": [],
      "source": [
        "def agent_node(state, agent, name):\n",
        "    result = agent.invoke(state)\n",
        "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwND2teK-WHm"
      },
      "source": [
        "### Agent Creation Helper Function\n",
        "\n",
        "Since we know we'll need to create agents to populate our agent nodes, let's use a helper function for that as well!\n",
        "\n",
        "Notice a few things:\n",
        "\n",
        "1. We have a standard suffix to append to our system messages for each agent to handle the tool calling and boilerplate prompting.\n",
        "2. Each agent has its our scratchpad.\n",
        "3. We're relying on OpenAI's function-calling API for tool selection\n",
        "4. Each agent is its own executor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NxLyHJt5-eUx"
      },
      "outputs": [],
      "source": [
        "def create_agent(\n",
        "    llm: ChatOpenAI,\n",
        "    tools: list,\n",
        "    system_prompt: str,\n",
        ") -> str:\n",
        "    \"\"\"Create a function-calling agent and add it to the graph.\"\"\"\n",
        "    system_prompt += (\"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
        "    \" Do not ask for clarification.\"\n",
        "    \" Your other team members (and other teams) will collaborate with you with their own specialties.\"\n",
        "    \" You are chosen for a reason! You are one of the following team members: {team_members}.\")\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                system_prompt,\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "        ]\n",
        "    )\n",
        "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "    executor = AgentExecutor(agent=agent, tools=tools)\n",
        "    return executor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6kmlR9d-1K5"
      },
      "source": [
        "### Supervisor Helper Function\n",
        "\n",
        "Finally, we need a \"supervisor\" that decides and routes tasks to specific agents.\n",
        "\n",
        "Since each \"team\" will have a collection of potential agents - this \"supervisor\" will act as an \"intelligent\" router to make sure that the right agent is selected for the right task.\n",
        "\n",
        "Notice that, at the end of the day, this \"supervisor\" is simply directing who acts next - or if the state is considered \"done\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "S2MXA83mrYE2"
      },
      "outputs": [],
      "source": [
        "def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:\n",
        "    \"\"\"An LLM-based router.\"\"\"\n",
        "    options = [\"FINISH\"] + members\n",
        "    function_def = {\n",
        "        \"name\": \"route\",\n",
        "        \"description\": \"Select the next role.\",\n",
        "        \"parameters\": {\n",
        "            \"title\": \"routeSchema\",\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"next\": {\n",
        "                    \"title\": \"Next\",\n",
        "                    \"anyOf\": [\n",
        "                        {\"enum\": options},\n",
        "                    ],\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"next\"],\n",
        "        },\n",
        "    }\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "            (\n",
        "                \"system\",\n",
        "                \"Given the conversation above, who should act next?\"\n",
        "                \" Or should we FINISH? Select one of: {options}\",\n",
        "            ),\n",
        "        ]\n",
        "    ).partial(options=str(options), team_members=\", \".join(members))\n",
        "    return (\n",
        "        prompt\n",
        "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
        "        | JsonOutputFunctionsParser()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd0zfyq48jKb"
      },
      "source": [
        "## Task 3: Research Team - A LangGraph for Researching A Specific Topic\n",
        "\n",
        "Now that we have our RAG chain set-up and some awesome helper functions, we want to create a LangGraph related to researching a specific topic.\n",
        "\n",
        "We're going to start by equipping our Research Team with a few tools:\n",
        "\n",
        "1. Tavily Search - aka \"Google\", for the most up to date information possible.\n",
        "2. Our RAG chain - specific and high quality information about our topic.\n",
        "\n",
        "Let's create those tools now!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNsVTZrH_alw"
      },
      "source": [
        "### Tool Creation\n",
        "\n",
        "As you can see below, some tools already come pre-packaged ready to use!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ce7FKTZDgAWG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIR7cbTL9agM"
      },
      "source": [
        "Creating a custom tool, however, is very straightforward.\n",
        "\n",
        "> NOTE: You *must* include a docstring, as that is what the LLM will consider when deciding when to use this tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "sSwO2L_UqFhm"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, List, Tuple, Union\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def retrieve_information(\n",
        "    query: Annotated[str, \"query to ask the retrieve information tool\"]\n",
        "    ):\n",
        "  \"\"\"Use Retrieval Augmented Generation to retrieve information about the 'Extending Llama-3’s Context Ten-Fold Overnight' paper.\"\"\"\n",
        "  return rag_chain.invoke({\"question\" : query})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxsMnqjpBTCj"
      },
      "source": [
        "> NOTE: We could just as easily use the LCEL chain directly, since nodes can be LCEL objects - but creating a tool helps explain the tool creation process at the same time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDHCajO4_gB2"
      },
      "source": [
        "### Research Team State\n",
        "\n",
        "Since we're using LangGraph - we're going to need state!\n",
        "\n",
        "Let's look at how we've created our state below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "mXminK9d_1fa"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import operator\n",
        "\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "import functools\n",
        "\n",
        "# class ResearchTeamState(TypedDict):\n",
        "#     messages: Annotated[List[BaseMessage], operator.add]\n",
        "#     team_members: List[str]\n",
        "#     next: str\n",
        "\n",
        "# def agent_node(state, agent, name):\n",
        "#     result = agent.invoke(state)\n",
        "#     return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvPM5msq_18C"
      },
      "source": [
        "Notice how we've used `messages`, `team_members`, and `next`.\n",
        "\n",
        "These states will help us understand:\n",
        "\n",
        "1. What we've done so far (`messages`)\n",
        "2. Which team members we have access to (`team_members`)\n",
        "3. Which team member is up next! (`next`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu7B_6qHAFjK"
      },
      "source": [
        "### Research Team LLM\n",
        "\n",
        "We'll be using `gpt-4o-mini` today. This LLM is going to be doing a lot of reasoning - but we also want to keep our costs down, so we'll use a lightweight; but powerful, model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "dTNqrip8AcKR"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfb_VCNKIy9w"
      },
      "source": [
        "##### ❓ Question #1:\n",
        "\n",
        "Why is a \"powerful\" LLM important for this use-case?\n",
        "\n",
        "A powerful LLM is crucial because it enables advanced reasoning, long-context understanding, and accurate tool use. In agent workflows, the LLM isn’t just generating text—it’s deciding what to do next, when to call tools, and how to interpret intermediate results. We need strong reasoning ability to ensure the agent can chain steps together, adapt to edge cases, and avoid shallow or incorrect decisions.\n",
        "\n",
        "What tasks must our Agent perform that make it such that the LLM's reasoning capability is a potential limiter?\n",
        "\n",
        "Tasks like:\n",
        "\n",
        "Tool selection and routing logic (deciding what to call and when)\n",
        "\n",
        "Multi-hop question answering (breaking down and solving multi-step queries)\n",
        "\n",
        "Interpreting retrieved documents (e.g., grounding or filtering context)\n",
        "\n",
        "Self-correction and retry logic (deciding if a result is insufficient and looping back)\n",
        "\n",
        "Each of these requires structured thought, not just fluency. If the LLM lacks sufficient reasoning strength, the agent may:\n",
        "\n",
        "misuse tools, misinterpret context, get stuck in loops, or produce unreliable outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_1LuMKAekf"
      },
      "source": [
        "### Research Team Agents & Nodes\n",
        "\n",
        "Now we can use our helper functions to create our agent nodes, with their related tools.\n",
        "\n",
        "Let's start with our search agent node."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzx6wuPoAlPq"
      },
      "source": [
        "#### Research Team: Search Agent Node\n",
        "\n",
        "We're going to give our agent access to the Tavily tool, power it with our GPT-4o Mini model, and then create its node - and name it `Search`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "FIlLPxj7Atpj"
      },
      "outputs": [],
      "source": [
        "search_agent = create_agent(\n",
        "    llm,\n",
        "    [tavily_tool],\n",
        "    \"You are a research assistant who can search for up-to-date info using the tavily search engine.\",\n",
        ")\n",
        "search_node = functools.partial(agent_node, agent=search_agent, name=\"Search\")\n",
        "\n",
        "# def agent_node(state, agent, name):\n",
        "#     result = agent.invoke(state)\n",
        "#     return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emLtesudA9Dd"
      },
      "source": [
        "#### Research Team: RAG Agent Node\n",
        "\n",
        "Now we can wrap our LCEL RAG pipeline in an agent node as well, using the LCEL RAG pipeline as the tool, as created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "z-nnAG9XA_p7"
      },
      "outputs": [],
      "source": [
        "rag_agent = create_agent(\n",
        "    llm,\n",
        "    [retrieve_information],\n",
        "    \"You are a research assistant who can provide specific information on the provided paper: 'Extending Llama-3’s Context Ten-Fold Overnight'. You must only respond with information about the paper related to the request.\",\n",
        ")\n",
        "rag_node = functools.partial(agent_node, agent=rag_agent, name=\"PaperInformationRetriever\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA5z6T1CBeSc"
      },
      "source": [
        "### Research Team Supervisor Agent\n",
        "\n",
        "Notice that we're not yet creating our supervisor *node*, simply the agent here.\n",
        "\n",
        "Also notice how we need to provide a few extra pieces of information - including which tools we're using.\n",
        "\n",
        "> NOTE: It's important to use the *exact* tool name, as that is how the LLM will reference the tool. Also, it's important that your tool name is all a single alphanumeric string!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "J0g8CQMBrtFs"
      },
      "outputs": [],
      "source": [
        "supervisor_agent = create_team_supervisor(\n",
        "    llm,\n",
        "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following workers:  Search, PaperInformationRetriever. Given the following user request,\"\n",
        "    \" determine the subject to be researched and respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. \"\n",
        "    \" You should never ask your team to do anything beyond research. They are not required to write content or posts.\"\n",
        "    \" You should only pass tasks to workers that are specifically research focused.\"\n",
        "    \" When finished, respond with FINISH.\"),\n",
        "    [\"Search\", \"PaperInformationRetriever\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qohn0DcgB_U1"
      },
      "source": [
        "### Research Team Graph Creation\n",
        "\n",
        "Now that we have our research team agent nodes created, and our supervisor agent - let's finally construct our graph!\n",
        "\n",
        "We'll start by creating our base graph from our state, and then adding the nodes/agent we've created as nodes on our LangGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResearchTeamState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    team_members: List[str]\n",
        "    next: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "p0s2GAgJCN8G"
      },
      "outputs": [],
      "source": [
        "research_graph = StateGraph(ResearchTeamState)\n",
        "\n",
        "research_graph.add_node(\"Search\", search_node)\n",
        "research_graph.add_node(\"PaperInformationRetriever\", rag_node)\n",
        "research_graph.add_node(\"supervisor\", supervisor_agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33qixRGNCaAX"
      },
      "source": [
        "Now we can define our edges - include our conditional edge from our supervisor to our agent nodes.\n",
        "\n",
        "Notice how we're always routing our agent nodes back to our supervisor!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "yYSJIhijsGyg"
      },
      "outputs": [],
      "source": [
        "research_graph.add_edge(\"Search\", \"supervisor\")\n",
        "research_graph.add_edge(\"PaperInformationRetriever\", \"supervisor\")\n",
        "research_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\"Search\": \"Search\", \"PaperInformationRetriever\": \"PaperInformationRetriever\", \"FINISH\": END},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgGcuZzkCj1-"
      },
      "source": [
        "Now we can set our supervisor node as the entry point, and compile our graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "1l-1I2Z3CnPX"
      },
      "outputs": [],
      "source": [
        "research_graph.set_entry_point(\"supervisor\")\n",
        "compiled_research_graph = research_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDwQpYTSEY13"
      },
      "source": [
        "#### Display Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "l8n6SXhpEa2b",
        "outputId": "6dac5e4e-daed-4d7a-d629-cd83119e7e2c"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAERAgADASIAAhEBAxEB/8QAHQABAAIDAQEBAQAAAAAAAAAAAAYHAwUIBAECCf/EAFIQAAEEAQIDAwYJBwgHBwUAAAEAAgMEBQYRBxIhEyIxFBUXQVaUCDJRVGGRldHSFiM2U3SB0zdCUnF1sbKzJCYzNDVVtBglJ2KCg5NDcqGiwf/EABoBAQEBAQEBAQAAAAAAAAAAAAABBAIDBQb/xAA0EQEAAQEGBAMHAwQDAAAAAAAAAQIDESFRkdEEEhMxQXHBFDNhYpKhsQUjMkKBwvAiUuH/2gAMAwEAAhEDEQA/AP6poiICIiAiIgIiICIiAiIgIiICIiAvxJKyFhfI9rGN8XOOwC1ObzFiGzFjcZGybKztLwZQTDWjB2Msu2x236NYCC89AQA57PJHoLF2JBPl2Oz9vcntskBI1u/TZke3IwbdOjd/lJO5XtFFMRzVzd+VuzbF2qMMxxDstRBHiDZZ96+flVhf+cUPeWfevjdKYRoAGHx4A6ACqz7l9/JXC/8AJ6HuzPuXX7Px+y4H5VYX/nFD3ln3r008vRyDtqt2vZPyQytf/cV5vyVwv/J6HuzPuXmt6F05eaRNgse4+p4rMa8f1OA3B+kFP2fj9jBvUUWlhu6LabEM1nJ4MHeevM4yz1Gf04nfGkY3xLHEu23LSdgx0milZPEyWJ7ZI3tDmvYdw4HwIPrC866OXGJvhJh+0RF5oIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgi+hNshVv5t+zp8lblcHfJBG90cLfoHK3m2HTme7x33Ps1rrjBcOtN28/qTJwYjEVdu1tTk7AkgNAABLiSQAACST0C8nDgeT6Wjou3EtCxPTeCNurJXAH+ot5XD6HBQr4UmmKureElqjc05ndSwNt15jFpmZseRqlrwRYgDvjvZ48mxJ3WjiPe1R8ft4fZZ7vLlvha8Oa3DvVWrMZmH5eLT0IdZoNqWIbIkc09ix0b4w9jXkbCRzeQdSTsCvmC+Fnw+ucMdMaxzOVODZnI2tjoPrWJZ/KBG180UbBEJJmsLtu0azlPQg7EKi8BgOJ2rtB8acK+rqXP6ft6ZfXw1/WGGjx+ZsWyx3+jjoHzM28HPHxiANuu/kh1BxC80cEIKOitWadxuH0+MZeytPSUFrNVrsVdkRjYLLHiCF+w2kIaHAncgDpnR07kfhHcN8Vo3T+rLOq6jNOZ+22hj8k2OR8Us55u44taez25H7l/KG8p3IUJi+GloTI8V9KaNxbreQhz0DpG5PyK1G2KRz2MgYI3QbuDy527yWtZy949enMml+F+s2cL+H2j8xojUJvYXi1WuZJsuMfJA6m90hfO17G8joR15nt2YOYfKF0RxKx2awPwzeHmrGabzOX0/NgZsLLexVN1iOpPJOSHTlv+zYA4EuPTbf5Cg6SUY0Ttj35nCN2EOLt8ldo32bBIxsjG/wBTedzQPkaFJ1GNKjynUOqrzd+yfcjrMJG3N2ULA4j/ANbnt/raVos/4VxPw1vj0mVjtKToiLOgiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiCN5GCXTmWsZmrA+xStBvnGtAxz5eZoDWzxtG5cQ0crmgbua1vL1Zyv3lDIVcpVZZp2IrVd/xZYXhzT+8L0LQZDRGLu3JLkTZ8bdkJMlnHWH13SHbbd4YQHnbbq8HwHyBe/NTXERXhMeP+/78F792/RRf8iJx4apzzR6h28R/vj3UT1/j8rpqTTDaeqcyRkc1XoT9rJCfzT2vLuX82O93R8v9SvTs/8Av9pLozWoii/5E2ParPf/ADQ/wk/IKKfdt3N5u/EehikvOiafoPZBhI+j1+B6JyWcd6/tP/hdGb05jPyS2JMVhnMsZcjZ7yOeKkD/APUm29ex7se4c8/I3me3ZYXEV8Di69CtzdjC3bmkO73uJ3c5x9bnEkk+skr9YzFU8NUbVo1oqldpJEcLA0bnxJ28SfEnxK9a4qri7ko7fkERF5IIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICr3i/t22hN9/0nqeA/8AJKrCVe8X2kzaE6E7aoqHo3f+ZL9SCwkREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBV5xf27bQe/L+lFTbff+hL4bKw1XvF4EzaE2G/+s9Tfx6dyX5EFhIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIotmNV3vOE9DCUYLk1YgWZ7c7ooYnEAhg5WOL3bEEjoACOu/RelnZ1Wk3UrdelKKEefdYfMMH73N/DTz7rD5hg/e5v4a0ey15xrBcm6KEefdYfMMH73N/DTz7rD5hg/e5v4aey15xrBcm64q+GH8MOzwa4mYbTF7QktytjrlXOVMl5ybG27GGODmhhiPJs9z277n4m/r2HT3n3WHzDB+9zfw1UXHzgHZ+EJZ0rPn6OHhkwN4WQ6GzLvZhOxkruPZjZri1vX1bHbxT2WvONYLlz8J9aXuIvDnAanyOEdpy1lawtebH2O3dCxxJj3fyt3LmcrtthtzberdS1QePM6uiY1jMdgmMaAGtbamAA+Qfm198+6w+YYP3ub+GnstecawXJuihHn3WHzDB+9zfw08+6w+YYP3ub+GnstecawXJuihHn3WHzDB+9zfw1+m6h1ZCeeXFYiwxvUxwXZGvcP8Ayl0W2/0HYfSE9lrzjWC5NUXiw2Xr53HRXaxd2Um4LZG8r2OaS1zXD1Oa4EEfKF7VkmJpm6e6CIigIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAq/0wd7upCfHzvN1/wDSwKwFX2l/981J/a8/9zFu4b+Nf9vy6jtLfIiL1ciIiAiIgIi19HO08lk8nj4HSm1jnsjsB8EjGgvYHt5XuaGv7rhuWEgHodiCEGwREQEREHk4an/urKj1DLXNh/7pKlyiPDX/AIXlv7Wuf5pUuWbivfVeaz3ERFlQREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBV9pf/fNSf2vP/cxWCq+0v8A75qT+15/7mLdw38a/wC35dR2lvlzZxYGotPar1ZqLNWtWSaSriOalmNH5gNbg444WmXymgXNE2zw+Rzi2XuOA5Rtsuk1AtQ8C9E6py93JZLESSz33NddhivWIa1wtAaDPAyRsU3RrR32u3AAPRd1RfDlBK2rr81z4QU7czafUx1avNj3mw4NqtdiI5OaLr+bBcS/u7dST4qNaFbkOIXETSmIy+qc+zHScM8Vk5qdLL2Kr7Fp0sjXWHPje1/NsRzEHvbt5t9gFc2ouCujtVZW7kcjipJJ70DK1xkF2xBDbjYCGNmhjkbHLygkAvaSPVtsFE7vwdcTk+JMOSsQNj01S0xUwNCGpkLNe5A6GaZ2wljc1/IY5GtP5wl2x5gfFczEimdPcSNV6un0Rpm8/VmoMdFVzUs8umLsVS9lPJch5JA+Sd00J5Wx953I8Oc5zSQRvtIZ5teW8Rw/wOayOo9Ni3rizjo55r0bcjZxXkViRjZ5IJHtLxsWc3MXAxtf8YAq8chwV0ZkMDhMOcKKlLCNLcacfZmqTVARs4RzRPbI3mHxu93vE7r0Y/hLpPFVMHWqYdkMWFvPyVLlmk5m2nskY+Z7i7eVzmyybmQu35t/EAicsiktXaqz3DZvEfQNPMZKzmMs/H/knav3JbFiMXtqjg2V7i78xLFJL49A4FfvI1tZ3sxxM05p/P5G2/FZbBwRVrOXfBYs1RQhfPBDYduYpZdnOLxsSeYkgklXrm+HOnNR6uwOp8jjGWs7gu1832zI8dj2jeV+7Q4Nf08OYHlJJGxO68Ob4P6Q1FLmZchiBPPl7MF23MLErJDPBGIopY3NeDE9rGhodGWnx+Uq8sih7etrlLCHSuOymsdOZK9qrFYjJ1NQ3G2buJr2Q4k1rfNIXtl7Ita8yOLS47cp2Cw8YMvm+FcPFLTmE1LnZqEWimZ6rNeyc1m1j7XlEkR7Ow9xkDXtaDsXHYsdtsCQr4rcEtF19O5XCOwvldHKvZLedetTWZ7D2bdm508j3SlzOUcp5t2kbjZYoOBeiYNPZ/CnES2aWfiEOUkt37NizbjA2a19iSR0uzQTsOfpudtt1OWRItH6bOlsJHTfkr+Wnc4yzW8jZdPI+R23MRzHZjd/Bjdmt8AAFu0A2GyL0Hk4a/8AC8t/a1z/ADSpcojw1/4Xlv7Wuf5pUuWfivfVeaz3ERFlQREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBV9pf8A3zUn9rz/ANzFYKrWxkJKWfuP07UOp6d25KLTcfMzejZjYxsjHOc4M67DulwcHc3Q7nk28NVH/KmZuvdRkk6LSeds97GZX3ql/HTztnvYzK+9Uv461cnzR9UblzdotJ52z3sZlfeqX8dPO2e9jMr71S/jpyfNH1RuXN2irbVfHHH6I1Xp3TWaxF6lntQS9jjaHb1XyTu8NyGzHkaT0DnbAnpupFkdWZbFGoLGjcyDanbWi7OSrJ33Akb8sx5R0PeOwHrKcnzR9UblyTotJ52z3sZlfeqX8dPO2e9jMr71S/jpyfNH1RuXN2i0nnbPexmV96pfx087Z72MyvvVL+OnJ80fVG5c3aLSeds97GZX3ql/HX6bkNRWO5FpK1BIejX3LlZkQ+lxjkkcB/U0n6CnJ80fVG6XPBonROIy2M1I90EtOzezMz7FvHWZKliV0Up7Mukic1x28Nidi3ukEdFKbeAzUbr0uN1JLHLZsxzRxZGrHYgrsHR8TGs7N+zh13c9xB8OnRcqfCF+Frqz4JWoocBLoaDMYy+HXKmdktPjjuSvIfOA0A8hZI8tDC4kM5D610D8HDi1Y448G8DrO5RgxlzI9v2tKvKZGw8k72N6nruWNY7r/SXz7eqK7WqqnteT3Sqe/qWi+y44mnkoTdYyu2paMcgrH4z3iRobztP80O7w8Nj0J+tqlR0gv0sljgMi3GxPmpve2Z7viSNMfMBG7w53coB6O2OwUiReCPBi8/jM55V5tyNTIeSWX07Hks7ZexnZ8eJ/KTyvb62nqPWF71rMppnEZt1V2QxdO86rbZfrusQNeYbDBsyZhI7rwOgcOuxI32Xgi0XFSMHm7K5bHsZfdfljbcNhs5d8eJ3biTliP9CPl5f5vKgkSKO16mp6Jpsdfx+VjNt5syTwOryNrn4jWcpc0vb4EkAOH9H1/aGocoZcZXyWnbVWe5JOySWpNHYr1QzcsdI/drtpB8XZh2PR23TcJCij2K1/gMuMO2PItqWsuJnUKORjfSt2OxP53lrzBku7PFw5egIJ6EKQNcHtDmkFpG4I9aD6iIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiLX5LN1cVYoV5u2fPem7CFkML5CXbFxLuUEMaACS52wHQb7kAhsFoczqkVJL9HF05M1nKsDJ/N8LhGNnu5Wc8rtmM8HO2J5uVriGu6A4IcVldSVYX5x3myCSCxBZw9KftGSB5LWOfPyNeHCP1M2Ac93eeGtct7jsfVxGPrUaNeKpSrRNhgrwMDI4o2gNa1rR0AAAAA8AEGpsads5ezI7K33vqR24bVWrRdJW7PsxuGyPa/eUF/eIOzSA1paQCXbqGCOtGI4o2RMBJ5WNAG5O56D5SSVkRAREQERePM5enp/EXspkJ2VaFGB9mxPJ8WONjS57j9AAJ/cg/nRqv4LXGC38KSXW1LM1uI9jAZzG2LdhsjKMzA4CYxtikfyNETAzuiQnlliIB3cG/wBANYzSQvwHJLk4ubKwtd5ti5w4EP6Tf0Yv6R9R5VquDuJt0tGtyeTrvq5nP2JM1egl+PDJOQ5kLvpiiEUP/tevxW21xOaeMpWe1ykbYslT5m4lgfI8PsMjIe31xd/eQjqGNcR4IJEiIgIiICIiCCcZuC+meO+iZ9MaprySUnvbLFYrODJ68g8HxuIIB23HUEEE9F9yPBjTMssVrDVpNIZSGJkEOR024UpGxsHKxj2NHZzMaBs2OZj2D1N6BTpEFdnMa70RsMrjY9cYpvjkMKxtfIRj5ZKr3ckmw8XRPDj/ADYvUpNpfXWB1mLQw+Sitz1H9naqEGOzVf8A0ZoXgSRO9ez2g7dVvlGtWcOsBrSaCzkaXLk6zS2rlKcjq92sD1IjnjIe0E+Ld+U+sEIJKirsO11oP4//AIg4Rn89ojrZeFv0juw2P3di7b1PKk2ktc4TW9exJh7wnlquEdqpKx0Nmo8jcMmheBJE7bryvaCR18EG+REQflzGvLS5ocWndpI8DttuP3E/Wo9S4fYLENxrMVTOEgxzJ2VauKlfVrMExJk3gjIjf3iXDmaeV3UbFSNEEcp4PO4ptGODULslXr1pI5fOtVj57Mh6xvMkXZtby+BAYeYfIepV8zn6jKjMlgWTPNSSW1YxVpskcczfCNrZAx7uceB26HodvEyNEEeq68w8roI7M0mLsy0DkjXyULq74oGnZ7n8wAbyn4w33Hj4EFb2vYitwRzwSMmhkaHskjcHNc0jcEEeII9a+yxMnifHIxskbwWuY8bhwPiCPWForGhcNJLJPXrOxtp2OOJZYx8jq74q2+7WM5CA3lPVpA3b1223KCQIo5Jhc9QbIcdnRYEePbWr18pXEjTYb4TySM5XnmHRw+XqNuoPyxqDM4plqS7gJLcFenHP2uKmbM+aXwkjZE7ld08QdzuPkPQhJEWkZrTC+U26815lOepHDLOy4DB2bZekZJeAOp7vQ9D0PXot2gIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIC89+/VxVGzdu2YadKtG6aezYeGRxRtBLnucejWgAkk9AAsWWy9fC14pbHau7WaOvHHBE6V75HuDWgNaCduu5d4NaHOcQ1pI8FHD2rlytksu8C5XM7YK1WZ/k7I3u2aXNOwfIGNA5iOhc8N2DjuGCS1k9TNmjoGXDY8trSwZUtY+Syx3fkayJ25j7vK3meObdz9mDlDjtMVgsfgzdNCnFVddsvuWnxt708ztgXvPi47Na0E+DWtaNg0Ae9EBERAREQEREBV7r/8A121LjNDxNbLS7mUzx36MqMf+YgO3rnlYRsehjgnB8RvJtY6qi0jhXWzA69dleK9HHxODZbthwPJCzfpudiST0a1rnO2a0kebQulZdN46zPkJIrWfycxuZS3CHBkk5AaGs5uojja1sbAevKwE7uLiQkq1upcY/NafyNGK3coS2IHxstY6RrLETiOjo3O7ocD1HN0+XotkiDwYHLDPYPHZMVLdAXK8djyW/CYbEPO0O5JGHq1432LfUQQvetBgYJ8VmMpjnQ35aT3eXwXrdkTMLpXvMkDN++wRkAhp3aGyNDTs0tbv0BERAREQEREBERAUZ1Zw8w+r7EF2eOSjm6zCypmse/sbtZpO5ayUDcsJAJjdzMdt3muCkyIK7/K7PcOwWa0EWTwbejdUY+BzOyb8tyuN+yA6bzMJj8XObC0Kf1rMN2tFYrysnrysEkcsTg5r2kbhwI6EEddwsqgNrSd/QVh2R0ZUbPjXOMl3SzHNijlJJc6WoXEMimJJJYS2OQ+JjcTIgnyLXae1Dj9VYatlcXY8ppWASxxY6N7XAlrmPY4BzHtcHNcxwDmua5rgCCBsUBERAREQEREHmyGOqZelNTvVYbtSZvLLXsRiSN4+RzTuCP61pcjoirZGWloXb+Dv5MQCW9j5++wxbchYyQPiadhynud4dDvsNpGiCPXWanpS5CenJjMtFJNCalGwH1HQx9BMHTN7QSH+c0dm3r3SevMPkWtIGWLkV6hdx/Y2xVikfG2ZtgHwkb2TnlrPUTIGEEdQBsTIlzXxz4v5LQeqp8dQtYXFiLF2csZ81HJL5Y9krY2VYGskYe0c5469895oDHboOiRlqbt9rMZ2Ox2Kedanzhn1qnsrxLwmmcXp2xqV8mDvZprewouhkllM/Zdo6HaNpJeACANt3EbAEkBRLWnH7F4fT+HzWHvQSUHakr4XLHKVZoJaTHAulDo3hj45Gt5SOdvgR0O4QdHedanzhn1p51qfOGfWqUxnHDRmUw+ZyTcx5LXw3L5xbdqzVpa3N8TmjlY1+z/5vd7x6Dcr8Rcd9Dvw2XykmYkp1cSyKW829Qs1poI5HcschikjbIWOd0Dg0joevQoLu861PnDPrTzrU+cM+tUVf414G5hNSuwVt02ZxeIny0VW/RsVxNExji2VgkaztYi4Ac8ZI6jr1C1HD7I8WNV4LTWfuZnRseOyVatemqwYW2JmxSNa9zGvNsgO5XEBxaRv12Pgg6M861PnDPrTzrU+cM+tcn6r47awoaY1fZwmKxV/M4zWsemcfUmbI1liJ7K5HOQ//aF0zgHDZo6d3od5hf4ysyGneHOc0+yGajqjM18fM22x3aQMfFM6RuwI5ZWPi5DvuAQ4bIOgPOtT5wz60861PnDPrXLuX4+5TC6Y11kZqWOM2I1ezTNKSZz4a0TJBWDZ7T93bNa6dxcW7DYAbDxUy0ve4iwajpw56PT2c0/cge85TBskquqSAAsDo5ZZO1a/cgOYRsR1Gx3QXh51qfOGfWnnWp84Z9aorhNxJu674RVNU5FlODJTNtudDXDmxAxTSxt2DnE9RGN+viT4KNxcacxPwU4f6peMTj8rqd1OGe3bY8UKJljc90rm9oHFo5OUNMg6ubu5B0z51qfOGfWnnWp84Z9aobR3F2vNwtsaw1TPWo46rYmhdk6kMnk1qFs5ijsxM7zxHJ3XDq7od+Yjqs1/jRgreF1KcHbdNmcXiJ8rFWvUrFds0TWu5ZWdo1naxFwA54yR1HXqEF5+danzhn1p51qfOGfWqC4a8etNa6radpPycbNRZOgyz2Das8VeWURh07IJXt5JOQl27WvcQAd/Ara6d42aM1XmauMxmXdPZuc/kb5Kc8UFzkBLuwmewRzbAE/m3O6AnwCC6RlKhIAsM3P0r1KhdM8fdC6ptYZuMzMk8WWlENG0/H2Yq08uxPZCd8Yj7TofzZdzbjbbdX0gIiICIiAvJlctTwlJ1u9Ziq12uYztJXhoL3uDGNBP85znNaB6y4AdSvWo1Nbjzet2Y+LIRujxFcWbuPdT5y+SY7VniZ3RvKIpyWN73fYSWjYPD3YTH2S4ZLKQxRZiaIRSxV7EksMLQ5xDGcwA36jmeGtLy1u42a0DboiAiIgIiICIiAtZqHUVHS+Llv35HNhYQ1rIo3SSyvPRscbGgue9x6BrQST4BeXVmsaWkKsDp4rF69bf2NLGUWB9q5LtvyRtJA8Opc4tYwbue5rQSNZp7Sd25l4tSaoMU+bY0ipSgeZKuLa5uzmxEgc8hBIdMQCQS1oa0kEPzpfTl/I5j8qtSRCLLOjMVHGh4ezFwO2JbzDcOmfsDI9u4GwY0lrS98yREBERBqNRYGLNQQTMirnKUHus46xYa4tr2OzcwPPK5ri0h7muAI5mucPWsmFzcOXZPCXwtyNNzYrtaJ7ndhKWhxbu5rSW7EFri0cwIIHVbNa3LY6ezJXtVLM0NqrzuZCJeWGxu0jklHK7u78p5gOYcvQ7FwcGyRa3D5uLKtdC8Crk4Yon28e6Rr5axe3mDXcpIP8AOHMCWktdsTsVskBERAREQEREBERAREQV7qTl4dauo6grDssLnLkVDMwtHcbZlLYq1sddgS/khfsO8JIyT+a62EoFx7bH6EdeSyHk8mwly2x/9CSKF0jHjoerXMafA+Hgp1A90kMbnt5HuaCWn1HbwQftERAREQEREBERAXEvEfD5vH8TNRahdpvUGZ4gY7P+VaasQ05bGOsY8xtZ5J2g/NV2uDpedz+Vwfyv7wAC7aUWt4m3Jame2ElrnuIO48N0HLmlK2c1Ff4NWcljM/LkcfmslZzcmUx88bas8tKy8hrnjbsWyStjjc08nRoB36LV8QNNZ6LWmpsjX0xlMrWbxBwWUjir1HO7eCGhCJZYyRyuDXNI5t9uYbEgrrLzNc/UO+sJ5mufqHfWEHMedxfpC1Vr/U1rR2orOlpsLjcSKnkklG/clitSzPsQxyckm8Iewg7AuLNm8yh3EqfUdjhVxIrPkz+c0nHjKYp3dW4vyC75QbbeauCY43Sx8ux53s6E7cx6rs3zNc/UO+sLU6q4ewa1wNrC5rHOuYy0GiaDtXR83K4OHea4EdWg9D6kHPevPO3E/Vk2Rxums5Qq4XR+Zp2H38dJXfYtWmRNjrRNI/PFvZOdzR8zeo2J3G8l4QcD6GJ0boq/ayerq+Tq0KU01CxqG+2GOZsbHOjfXdLyhocNjGW7bdNtuivXzNc/UO+sL8HBWySRAWuO27gRudkHL7tJZz/WL/ubIfneLVLJR/6K/v1G+R81gdOsQ5Hbv+KOU9ehWXXWhc9pfjJpWvhcVbyGjsxqaHUEz6sLpGYq4yKVlgv2Hcjm7Rkm56B7ZP6S6RnZJTvU6diMxWLjntrgg8sha3mLebwDuXd3KTuQ1xG4aSPb5mufqHfWEHO2AgzOmMTxTmn0PZ1NRyGtZpJ8ZNEGvs499as180McjeWwAWnZu4DuVwB3Gx1OhdL0aXFzTdvhtpXUmj8C3yl2ooshUsY/HTRmJwiayvNsDKJS0h0TQAA7ckHZdP8Ama5+od9YTzNc/UO+sIOXeDvwcdH3uDNWzqbh9QfqeQXnzOyWNAtF3lE3ZlwcObfl5Nvo22USi0Bcu8OeH+J1rgdTyadh0dFXrw4uhPPLjcuD1lmrMBfztbyche0taQ8Hbddn+Zrn6h31hPM1z9Q76wg47ydrXGvOEnEajqjTefh1RfrUm18VHjZ3UzWidCOaIt5o+0kc+WR0YPO0ANIIj3Vj8YNPZTI8RprNLGXLVY6DzdLtq9d72GZ76xji3A253cruVvidjsOiv3zNc/UO+sJ5mufqHfWEHLWFhyuqsVwT07Bo/NYu7pZ0FzKvv499evAyHHywmFkzgGSGR8jQGtJIG/MG7ED0cN4sxgNU6SxWlKesKmnmyvZk9Paqxh8kw8Ahk28muPYC4tfyMa1kkrS1x8AN1075mufqHfWE8zXP1DvrCDjThXZvax4GcI9I47TeWjvwZjH5CW8aTxShrQW+3fOLO3Zkua0jk35+ZxG3rXfKr3SPD6vojA47B4bHGliqLBFXg7V0nI3ffbmc4uPifElWEgIiICIiAo5pK95fkNUObmH5RkeUMLYH1jCKHLXhBgaT/tBzc0nP8spHg0KRqAVeJWndP65zOm85rbHR5m1egdjsTkXxVJmRywxNZDCHOBsc0rZHBzQTvJyfzRuE/REQEREBEXkyuWo4HG2cjk7lfHY+tGZZ7duVsUUTB4uc9xAaB8pKD1qHah11M3Lv0/pqkM3qFoabHM/lqY1rhuH2ZPUSCC2Ju8j9wdms5pG63zjn+JvNHjPLNK6Vd0OVewR5C+3fr5PG4EwRkdO1eBIevI1nclMw07prF6SxMWMw9KKhSjLnCKIfGc47ue4nq57nEuc9xLnEkkkklBq9JaHi07YsZO7clzeo7jQ21lrIAcWg7iKJg6QwtPhG3/7nF7y57pOiICIiAiIgIiINfk8O3Ivhkjs2KFiOaKUz1C1r5GscT2T9wQ5jg57SCOgeS0tcGuHlxuoHeU18dlo4cfl5+3dDXZLztnjjeB2jHbDxa5ji09W8xHUDmO6XlyeNgy9CxTsh5hnjfE8xSOieA5paS17SHMOxOzmkEeohB6kUefdyGnJJTda7IYgeTQ15q0T5LTHOPI904G/M0HlcZG7bBzuZoDC472CeOzE2WGRksbvB7HAg/vCDIiIgIiICIiAiLHYsRVIJJ55GQwxNL3ySODWsaBuSSfAAetBAONbfPensfpCPvWNUX4se9g9VQHtbbj8g7COVu/hzSMHi4A2GoFoetJq3UFnXVyNzIZoHUcHBIOsVEvDnz7bbtdZcyN+3qjig3DXc4U9QEREBERAREQEREBERAREQEREBERB579GDKUbNOyztK1iN0MrOYt5muBBG46joT1C1WOyD8TkIsNkbNcPkby4177BdYtsYxvaF4c0d9pJJ5S7cd7p1A3q0GuGyR6at3IbzcZNjwLrbjqgtdk2M80gEfieaMPYeXZ2zzykHZBv0Xnx2Qr5bH1r1SQTVbMTZopB4PY4AtP7wQvQgIiICIiAiIgIiIC0uY1tp7T9oVsnnMdj7JHN2Nm0xj9vl5Sd9l7c1cdj8PetMAL4IJJWg/K1pI/uUR0lUjrYClIBzT2YmTzzO6vmkc0Fz3E9SST+7w8AtdjZU1UzXX2+CxnLZelLR3tTiPfY/vT0paO9qcR77H96zIvbpWOU6xsuDX5XX2gs7i7mNyGocJboXIX17FeW5GWSxvaWua4b9QQSD/Wv59cMPg1YLht8NTHWG5uhc4fY0yZuhknW2cjSN+xge4HbtGSFvTpu1nNt8n9FUTpWOU6xsYMPpS0d7U4j32P709KWjvanEe+x/esyJ0rHKdY2MGH0paO9qcR77H96elLR3tTiPfY/vWZE6VjlOsbGDU5jjDgKwrVsLO3VGZuvMVPHYqRr3SPA3JfJvyRMA6l7yPkHM4tafmJ0DczOSrZvWtqHK5GB4mqYqqXebcc8HdrmNdsZpR0/PyDcEbsbFu4H25LG18tTkrWoxJE/6dnNI6hzSOrXA7EOHUEAjqFsNCZOfNaLwd60/tbNinE+WTbbncWjd23q3PXb6V42tlTTTz0du2KfGG9REWRBERAXjymYoYOr5TkbtehX5gztbMrY28x8BuT4n5F7FA28uU1xnZrA7V+OdFUrB43ETXRMleW/IXF43PieVo9QWixs4tJm/tEX+nqsNn6UtHe1OI99j+9PSlo72pxHvsf3rMi09KxynWNlwYfSlo72pxHvsf3p6UtHe1OI99j+9ZkTpWOU6xsYMPpS0d7U4j32P709KWjvanEe+x/esyJ0rHKdY2MGH0paO9qcR77H9642+HpxVyTNMV9E8LGXX08w2eznbeAMLqk0cr+/C7kaZO1e5rnPLXMBbI4OEnank7PROlY5TrGxgob4HHwhGal4N47Ha5tDBakwYbQldlj2BtRNG0UrS/bmPKOV3id27n4yvP0paO9qcR77H96zInSscp1jYwYfSlo72pxHvsf3p6UtHe1OI99j+9ZkTpWOU6xsYMPpS0d7U4j32P709KWjvanEe+x/esyJ0rHKdY2MGH0paO9qcR77H96g2qeIOmte6i/J2bP4yHSdRrJ8rLNZYG5J56sps3PeiGwdKfiuBZH3g6UNn6J0rHKdY2MGH0paO9qcR77H96elLR3tTiPfY/vWZE6VjlOsbGDD6UtHe1OI99j+9PSlo72pxHvsf3rMidKxynWNjBh9KWjvanEe+x/enpS0d7U4j32P71mROlY5TrGxgw+lLR3tTiPfY/vT0paO9qcR77H96zInSscp1jYwYfSlo72pxHvsf3r63ijo9zgBqjEEnoALsfX/8rKidKxynWNkwbujfq5SpFapWYbdWUc0c8Dw9jx8ocOhXoUHwfLjNfuqVx2UGQoSWpomjZpljkiYH7eAcWybE7dQ1u/gFOFltrPp1XR2nEkREXggiIgIiICjWt+IeltAU436m1RiNMttB7a8mWuxV+0LQObkEjhzkbjcDfxHyplOJWlsNZfWt52kyyw7PhZJ2j2H5HNbuR+9UT8Laporj5wWy+Br5WJ2crDy7FPdBKNrLAdmblvQPaXM6nbvAnwWmnhbeqL6bOZjylbpXHwk4laa4iaVouwOscXrG1VpVjes4+SISB72dHywMJMBeWvPZuA2IcP5pU4XIPwG8JpTgJwdjjzN9lXVebl8tybDBIXRAbiKEkNIPK0k/Q57gulcfxR0nk5mQw5+k2V5AayaTsi4nwAD9tz9AVnheIpi+bOdJLpSlERZUEREBERAREQavVX6MZj9jm/wFR7TX6OYr9ki/wBSHVX6MZj9jm/wFR7TX6OYr9ki/wBfRsfcz5+i+DZIi5Eg1JXjZeqcR9f6y4ccRpLthte/ZnsQ4Vp7V3YGBo/0SWHk7PcSHmPeBIPVJm5HXaKsc1xSzkWrJtKaW07Dq7L4zGwX8pamyAx9eMSlwiYw8khdI/s5HBuwaABu/qtTlPhEMOjdL6ixGLoMoZqGSV9jUubhxFem+MhroXvc17nS83M3ZrCO4SXDpu5oFyIqQg+Eu7N6a0FkdPaZ88XNWXreMiqecWMZBPXbNzntWsc18fNC7vj+Z3gCe6dna41ahnyecjwWhJdQUNOzx08vNVyLRMLJjjkliqxGP8+Y2yt3LnR7noASnNAtxFzkzi1qzSereNFyngbGqsPgMhFblFvKms2pWGOryPjrMcx/M/pI8s7jd3fG3cugcNlYM7h6OSqlxrXII7ERcNjyPaHN3H9RCRN49iw8Lf5ONN/sEX+ELMsPC3+TjTf7BF/hCWvuZ84/Er4JSiIvnIIiICgOM/THWP7ZB/wBJCp8oDjP0x1j+2Qf9JCt3C/1+X+ULHi3aIubeK2awH/aQditY6/v6OwDdJ17VaGLVE2Hhksm5Ya53clYHu5Gges7AfIu5m5HSSLnrhjxIyeF0jr/JY61c15pTF5aODT+UyeQjjNiF0cXbF1uXYPhildIO1PMSGkDmIAWZvwsqkekNdZR2Kx2SyOlIqliavgc4zIVbMViQsb2dhsY2e0tfuxzARs31O3E5oF/oqql422tL6gnx2t9PxabhOFtZ2raq5Dyxr4K3KbEcg7JnJKxsjHcrS9pBOzzt1x6Z415i7ltJx6j0edOYzVgcMRbbkW2ZBJ2LpmRWYxG0RPdGx5HK6QbtIJBVvgWyi5m1Vxr1JxC+DlPrKriJ9G1rV7DijZrZUvsyh2ShinBDWMLGbbtB3PO1x3a0eM0z3HfOUbvEVuM0ZFkaWh3g3rM+W7A2IvJY7J7FohdvIGvcORxa3o08/e2bOaBcqLnDOcR8vLx7hy9mR8HD/D6OGpOWHMzQ80LucvnlrMi5ZXjlLBE95aAA8O5jyiZ6e425qbKaRbqXRo07idWO7LFXGZNtqRsphdNHFZiEbRE58bHbcrpACNiR4q80C3EVCYf4TOYyXDHEa3l0GYMfl8hQx1CqzLNfYnfPOYHu2MQDQ1+3Lue+DueQbE++3x21XUvazxjtBVJMrpOrHkb4jzp8mkrPidJH2MhrhzpT2co5HMa0FnV/UbuaBdiKntafCAfp6ng71DF4g4zKYuPKRXdRaigxMbw8bthjDmvc+TYgncNYNx3vHbV1uN+f1hr3hK7TGPqO0pqzDWspYbet9lO0MMHOC0Qv70QlBADwJC5wJYGguc0C9UVCaB43XMlozh9jdMadsZvUGdxU2UFXMZxxFWrFI1jpJ7jonveS+RjW7Rknc77Abr3x/COtXH6fx9TSMkmochnLmnbeNkvtY2lbrwOmJMoYQ+ItDXcwAIY7cNJHIXNAuxFzVxl4t38twp1VWvPn0RmMBqXF4vKTYzLva1kMs9WQyR2mticGOhm6ktaR3t15BqDT2J19oaDhfxKyes8ldy8cGUxJ1LLnK/m4seZ5pA+STsSzZpa8Fu52HXdTmHUCKlcp8Im5SpZ7UdfSTrWgsFkZMfezfnBrLH5qTsp5oq3ZkPijfzAkyNJDHENK0ud4+aq0TqXi5dyeEo5DTWk2UTXhr5Aic9qGkbDyfqXtk5ju48pYGjmBLg5oHQiKm8pxTn0/rLB2NW4izp97dPZfLWIq+YdPBBXrvrk9pE1jWSSlr999+5s5rS4O3THcc9QuOn35XQvmqDU8ErsEfOzZXy2BA6eKvZaIgIHSMY7YtMgBBB6q80C5EVVUuPVTLad4aZKhjDPY1nIAakljkNCJkD5bUj3ch5ux5CwjZu7iBuN1rMD8IW9lK2ms9b0g/H6I1JeioY3LnIB9neZxZXkmrdmOzjkdygESOI527gepzQLoRVzw04pZXiNqHUtcaabjcJhMndxDslJf532LEE3IOSLsx3HM7xcXd090B3VwsZWJvGpp/wAp2O/se3/nVlOVBqf8p2O/se3/AJ1ZTleXFd6PL1l1PgIiLE5EREBUNr/iJPq+xLSx1h9fAsJb2kEha678pLh1EfiA0HvDqeh2VlcWstLh+HuXlgeY5pmx1GPb4tM0jYuYfSOcn9yoeNjYmNYxoaxoADR4AL9V+i8JRXE8RXF903Rv98F7Re/MMEdaMRxRsijHg1jQAP3BftVxrfi5ZwGtK+k8Dp92o866i7JTROuMqRwwB3KCXuB3cXdA3b1jr1WisfCOgsUtBWcNp+xlvysdZhjg8obFLXmh2BY4EEHvkgu3AAHN18F+kq4qypmYme3n8I/Mw4XIvkkbZWFj2h7T4tcNwVTJ+ElXx2kdW5LNafnxuY07cZQnxMdls/ayyHaLkkDQCHdTvt0APitZhdb6oy/wjcHjszj7umo3aflmlw4yHlFaR3aHlkBbs1zh8XctBBb8mxPE8XZX0xTN992fjN2OXYdOaG13Y0HKyGR8k+n+jZKxO/krf6cXrDQPGMdNh3QD0d0DDNHYiZLE9skT2hzHsO7XA9QQfWFy4rm4H5J13QzajyXHG2ZaTSfUwbOjb/U1j2tH0NC+D+s8JRFMcRRF033Tu6vvhYCIi/JAiIgIiINXqr9GMx+xzf4Co9pr9HMV+yRf4ApDqr9GMx+xzf4Co9pr9HMV+yRf4Avo2PuZ8/RfBsXDcEAkE+sepUlnNGcX8xo3KaOu3tIZ2hegmpO1DkRMy0YX7jnfTZF2TpA0+qRrSQDsPBXcisxejnPPfBcZT1DSyWOwGldbwtwdLDS19Ytc18TqrXMjnikbFL1e1wD2co3LGnmW2r8FNRaV1HpbNafo6Pmlx2ClxEuPkglpUqUsk4mdYqxsbJ4kuDmEtLgB3x1CvZFzywOf+H/AfVelcjolmRv4q7S01qLLZXyyKSRs9uC5DZDSYuz5WSCSwN2hxbygkO36Ldz8OuIOltQ6xGislgquI1RfGTddyQkdaxdh0UcUzo4gxzJwRE1zQ9zAHE78wVyorywKmdwlzBx3GWv5XTfJrMvNB7nu/N746KrvNszu9+Mnu83dI9fRWDozDTad0fgsVZdG+xRoQVZXRElhcyNrSWkgHbcdNwFuEVuuBYeFv8nGm/2CL/CFmWHhb/Jxpv8AYIv8IUtfcz5x+JXwSlERfOQREQFAcZ+mOsf2yD/pIVPlAcZ+mOsf2yD/AKSFbuF/r8v8oWPFu1XzuG9ixxztazsClPiZNOQ4hkEm7phMy1LKXcpby8vLIBvzb779PWrBRel16K941cPL/EHTOJqYryB1nF5aplG0cnzNqXBC/fsJS1riGnfcHlds5rehVE8eOHWssPpXiZqrKz4VlXP4fHVJa+Pkk5sdLBc/Nti5owJmES7l7uQ82+zdttuuEXM03ik8xwd1NxQ1HYta7nw9THw6eyGBqRYSSWV8rrgYyew/tGN7PuRtDYwX7End52663hX8H2zo3Pafnu6N4d0Bh4y1+axNJ7r914jLGyNBjYK7iTzO78u/UDbfcX8ivLHcUX6C89/2ZMLw68rx3nulJQfJY7WTyYiC/FYfs7k5urGEDdo67b7Dqt5Lwny76PGeEWaXNrR0hx5L37Rc2OirDtu53e+wnu83d29fRWwicsClW8BruTu2IMrbqjFXNARaPsGs9xlEu7+0kaC0Dk5X9CTvuPAJhuGOuc1kdA19YWcC3EaOmbcilxUs0k+SsMrvgie9j42tgAEjnFodJudhuArqROWBR+L4HZ2jwT4d6Pkt445PTuYxmQtytkk7F8de42eQRnk3Li0bDdoG/iQOqkFzhflbGpuKmRbYpiDVWHqY+k0vfzRyRQ2GOMvd2Dd5m7cpcdgeg6b2gicsCgtO8FNY6PzNe5jZtPW5bOmcZgZ7190rpsW+sx7Hvqt7MiVjy/m5HOi3c0E/IsWgeCWtdEM4UESYG0/R1a9h7Q8rnaLFOd0G07D2PSVoh6xnukn466CRTlgc+6K4G6w4bYvh/kcNPg7+pMDhJ8DkadyxNFUtQSSsmDo5mxOexzHxjxjO4cR08V79McCc7itT6V1BeyGOnyMWpclqPNNgMjYw6zSkrMirgtJcGDshu/l3DXHxPKrzROWBRWs+BGd1JNr50FrGhmoNS4bMV2zSSd2Co2oJWybMOzj5O/lA3B3buRudpfqfhtdi4i6b1jpR1Kher747MVpy6OK9jnEu27jXfnYn7PZuADzPaSA5WMit0Dmk/BYdj81moa+kuH2dx+Sys2RZmtQUnzXq0c0vaSQuhEe03KXPDHGZnTl3HTrueI3A3Veo7/EyviZsK3E6vrY8xyW7Esc1WesGN5SxsTmljms35ubcHpykdRfqKcsCruJvB+biPrOransww4N+mstgbjQ53lG9zsAHMHLykARv33I6lvQ9dolwr+D7Z0bntPz3dG8O6Aw8Za/NYmk91+68RljZGgxsFdxJ5nd+XfqBtvuL+RXli+8Upw/4DXtMcTNRZXJW6drS7WW49PUIXP7Sq29MJ7oeC0Nb+caGs5Se7vvt4KMcOfgvSaHt6foSaS4e2qeGsseNSyUnvylmKNxMZMXZtaybo3eXtXdRvy+pdJIpywIPwo0Nf0LT1NFflrzOyeoshl4TWc5wbDPMXsa7do2cAeoG438CVOERdRFw1NP+U7Hf2Pb/AM6spyoNT/lOx39j2/8AOrKcry4rvR5esup8BERYnIiIgiHFrEy5nh9loYGGSeFsdtjG+LjDI2XlH0nk2/eqGjkbLG17HBzHAOa4eBB9a6oVE6/4c2NJ2Jr2MrvsYN5LzFXiLn0/lHKOpj8SCB3R49Buv1P6NxdFETw9c3XzfHnl9sDvFzmXixwLt6u4gVtWYypgMtL5B5BYxupI5DB0cXMlYWAkPG+223h6+qywcEslUyvDCzA/D14tNTW578VKF1aN7pmgDsYwHDoQd+Yjfx9ewuGCxFajEkMrJoz4PjcHA/vCyL9HPCWXNNV2M4/eJ9HKhNUfB3y2pmcSw7I0qsuoL9TIYuVpe7sXwg9JRyjbfcju83jv6tju9PcONb2OL2L1tqe7g3tr4mTHPq4sygMcXcwLedve3JJJJG3QAHbc3AvzJKyFhfI9rGDxc47AJHCWcVRVF+f3mfWR+lc3BDGOpaGZbe0tOTsyXWg+tjtmxu/qcxjHD6HKvNDaCs66ljnmjkraf6OfYcOU2xv/ALOP18pHjJ4bHZpJ3LegIomQRMjjY2ONgDWsaNg0DwAHqC+B+s8XRNMcPRN833zs6uuh+0RF+SBERAREQePM03ZHEXqjCA+eCSIE+ouaR/8A1RDSVyOxgacIPJZrQsgsQO6Phka0BzHA9QQfrGxHQhTtaXMaK0/qGwLGUweNyM4HKJbVSOR4HybuBOy1WNrTTTNFfZfg8yLD6K9GeyeE+z4vwp6K9GeyeE+z4vwr36tjnOkbmDMiw+ivRnsnhPs+L8KeivRnsnhPs+L8KdWxznSNzBmRYfRXoz2Twn2fF+FPRXoz2Twn2fF+FOrY5zpG5gzIsPor0Z7J4T7Pi/Cnor0Z7J4T7Pi/CnVsc50jcwYsnlK2HqPs2pRHG3oB4ue49A1rR1c4kgBo3JJAHUrY6Fxc+E0Zg6FpnZ2a9OKOWPm5uR4aN27+vY7jf17L7itDacwVltnHYHGULDd+WatUjje3fx2IG43W8Xja2tNVPJR274nwgREWRBERAUDHLitcZyKwexdknRWqxedhKGxMicGnwJaWDceOzgfAhTxeTJ4mjmqvk2Qp171fcO7KzE2Rm48DsQRutFjaRZzN/aYu9fRYadFh9FejPZPCfZ8X4U9FejPZPCfZ8X4Vp6tjnOkbmDMiw+ivRnsnhPs+L8KeivRnsnhPs+L8KdWxznSNzBmRYfRXoz2Twn2fF+FPRXoz2Twn2fF+FOrY5zpG5gzIsPor0Z7J4T7Pi/Cnor0Z7J4T7Pi/CnVsc50jcwZkWH0V6M9k8J9nxfhT0V6M9k8J9nxfhTq2Oc6RuYMyLD6K9GeyeE+z4vwp6K9GeyeE+z4vwp1bHOdI3MGZFh9FejPZPCfZ8X4U9FejPZPCfZ8X4U6tjnOkbmDMiw+ivRnsnhPs+L8KeivRnsnhPs+L8KdWxznSNzBmRYfRXoz2Twn2fF+FPRXoz2Twn2fF+FOrY5zpG5gzIsPor0Z7J4T7Pi/Cnor0Z7J4T7Pi/CnVsc50jcwZkWH0V6M9k8J9nxfhT0V6M9k8J9nxfhTq2Oc6RuYMyLD6K9GeyeE+z4vwp6K9GeyeE+z4vwp1bHOdI3MGZFh9FejPZPCfZ8X4V9bwt0axwc3SmFDgdwRQi6f/AKp1bHOdI3MGvwXLldfOuVj2tfH0JKkszTuwSySRPDN/AkNj3IB6czd/EKcLBSo1sbVjq1K8VWtEOVkMDAxjB8gA6BZ1ltrSLSq+O0YEiIi8EEREBERBHMtw50xm7T7N3BUZbLzu+cQhkjj9Lm7E/vWu9Dejf+Rxf/LJ+JTRFpp4q3pi6m0mI85W+UL9Dejf+Rxf/LJ+JezH8MdKYudk1fAUe2Yd2ySxCRzT8oLt9j9IUoRWeK4iqLptJ1kvkREWVBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQf/2Q==",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        compiled_research_graph.get_graph().draw_mermaid_png()\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# display(\n",
        "#     Image(\n",
        "#         compiled_research_graph.get_graph().draw_mermaid_png(\n",
        "#             curve_style=CurveStyle.LINEAR,\n",
        "#             node_colors=NodeStyles(first=\"#ffdfba\", last=\"#baffc9\", default=\"#fad7de\"),\n",
        "#             wrap_label_n_words=9,\n",
        "#             output_file_path=None,\n",
        "#             draw_method=MermaidDrawMethod.PYPPETEER,\n",
        "#             background_color=\"white\",\n",
        "#             padding=10,\n",
        "#         )\n",
        "#     )\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfRvA2QfCqFL"
      },
      "source": [
        "The next part is key - since we need to \"wrap\" our LangGraph in order for it to be compatible in the following steps - let's create an LCEL chain out of it!\n",
        "\n",
        "This allows us to \"broadcast\" messages down to our Research Team LangGraph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "1G7hmEINCx3i"
      },
      "outputs": [],
      "source": [
        "def enter_chain(message: str):\n",
        "    results = {\n",
        "        \"messages\": [HumanMessage(content=message)],\n",
        "    }\n",
        "    return results\n",
        "\n",
        "research_chain = enter_chain | compiled_research_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGdoCdXWC7Pi"
      },
      "source": [
        "Now, finally, we can take it for a spin!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIDpFIg2sRUl",
        "outputId": "bb3803d4-5b32-4b0a-c8a1-1a1917425812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'PaperInformationRetriever'}}\n",
            "---\n",
            "{'PaperInformationRetriever': {'messages': [HumanMessage(content='The main takeaways from the paper \"Extending Llama-3\\'s Context Ten-Fold Overnight\" are:\\n\\n1. **Context Length Extension**: The authors successfully extended the context length of the Llama-3-8B-Instruct model from 8K to 80K tokens using QLoRA fine-tuning.\\n\\n2. **Efficient Training**: The training process was highly efficient, taking only 8 hours on a single 8xA800 (80G) GPU machine, utilizing a dataset with 20K instances, which included synthetic samples generated by GPT-4 and other datasets.\\n\\n3. **Performance**: The extended model demonstrated superior performance across various evaluation tasks, including NIHS, topic retrieval, and long-context language understanding, while still maintaining its original capabilities for short contexts.\\n\\n4. **Potential for Further Extension**: The authors suggest that with more computational resources, the context length could be extended even beyond 80K tokens.\\n\\n5. **Public Release**: The team plans to publicly release all resources related to the project, including the model, data, data generation pipeline, and training code.\\n\\n6. **Comparison with Baselines**: The paper includes comparisons of the zero-shot performance of their model against other models, indicating that while the long-context models may underperform the original Llama-3-8B-Instruct in short-context tasks, their model still outperforms other open-source models of similar scale.\\n\\nThese points highlight the advancements made in extending the context length of Llama-3 and the implications for future research and applications in large language models.', name='PaperInformationRetriever')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'FINISH'}}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for s in research_chain.stream(\n",
        "    \"What are the main takeaways from the paper `Extending Llama-3's Context Ten-Fold Overnight'? Please use Search and PaperInformationRetriever!\", {\"recursion_limit\": 100}\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHAgsbwIIhwj"
      },
      "source": [
        "##### 🏗️ Activity #2:\n",
        "\n",
        "Using whatever drawing application you wish - please label the flow above on a diagram of your graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH70eHGlJbq4"
      },
      "source": [
        "##### ❓ Question #2:\n",
        "\n",
        "How could you make sure your Agent uses specific tools that you wish it to use? Are there any ways to concretely set a flow through tools?\n",
        "\n",
        "Explicit tool routing (hard-coding logic):\n",
        "You can define a specific sequence using a RunnableSequence or graph where each tool is called in a fixed order. This gives you full control over the flow (e.g., Retriever → Summarizer → Fact Checker).\n",
        "\n",
        "System prompt steering:\n",
        "If you're letting the LLM choose tools dynamically, you can use system prompts or tool descriptions to strongly bias or instruct the agent toward specific tools for specific types of queries. Like here: \"...specific information on the provided paper: 'Extending Llama-3’s Context Ten-Fold Overnight'. You must only respond with information about the paper related to the request\"\n",
        "\n",
        "Tool-specific conditions:\n",
        "Use conditional nodes (like RunnableLambda or routing functions) to evaluate the input and decide which tool path to follow.\n",
        "\n",
        "Tool restriction:\n",
        "Limit the available tools in the agent’s environment. If the agent only sees the tools you want it to use, you reduce the chance of it doing something unexpected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iktcBorGXmAW"
      },
      "source": [
        "# 🤝 BREAKOUT ROOM #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejsHCZZ2EmwM"
      },
      "source": [
        "## Task 4: Document Writing Team - A LangGraph for Writing, Editing, and Planning a LinkedIn post.\n",
        "\n",
        "Let's run it all back, this time specifically creating tools, agent nodes, and a graph for planning, writing, and editing a LinkedIn post!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4awQtZ-oFUN-"
      },
      "source": [
        "### Tool Creation\n",
        "\n",
        "Let's create some tools that will help us understand, open, work with, and edit documents to our liking!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Dict, Optional\n",
        "from typing_extensions import TypedDict\n",
        "import uuid\n",
        "import os\n",
        "\n",
        "os.makedirs('./data', exist_ok=True)\n",
        "\n",
        "def create_random_subdirectory():\n",
        "\n",
        "    random_id = str(uuid.uuid4())[:8]  # Use first 8 characters of a UUID\n",
        "    subdirectory_path = os.path.join('./data', random_id)\n",
        "    os.makedirs(subdirectory_path, exist_ok=True)\n",
        "    return subdirectory_path\n",
        "\n",
        "WORKING_DIRECTORY = Path(create_random_subdirectory())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ptXilgparOkq"
      },
      "outputs": [],
      "source": [
        "# from pathlib import Path\n",
        "# from tempfile import TemporaryDirectory\n",
        "# from typing import Dict, Optional\n",
        "# from typing_extensions import TypedDict\n",
        "# import uuid\n",
        "# import os\n",
        "\n",
        "# os.makedirs('./data', exist_ok=True)\n",
        "\n",
        "# def create_random_subdirectory():\n",
        "\n",
        "#     random_id = str(uuid.uuid4())[:8]  # Use first 8 characters of a UUID\n",
        "#     subdirectory_path = os.path.join('./data', random_id)\n",
        "#     os.makedirs(subdirectory_path, exist_ok=True)\n",
        "#     return subdirectory_path\n",
        "\n",
        "# WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
        "\n",
        "@tool\n",
        "def create_outline(\n",
        "    points: Annotated[List[str], \"List of main points or sections.\"],\n",
        "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
        ") -> Annotated[str, \"Path of the saved outline file.\"]:\n",
        "    \"\"\"Create and save an outline.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        for i, point in enumerate(points):\n",
        "            file.write(f\"{i + 1}. {point}\\n\")\n",
        "    return f\"Outline saved to {file_name}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def read_document(\n",
        "    file_name: Annotated[str, \"File path to save the document.\"],\n",
        "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
        "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
        ") -> str:\n",
        "    \"\"\"Read the specified document.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    if start is not None:\n",
        "        start = 0\n",
        "    return \"\\n\".join(lines[start:end])\n",
        "\n",
        "\n",
        "@tool\n",
        "def write_document(\n",
        "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
        "    file_name: Annotated[str, \"File path to save the document.\"],\n",
        ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
        "    \"\"\"Create and save a text document.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.write(content)\n",
        "    return f\"Document saved to {file_name}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def edit_document(\n",
        "    file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
        "    inserts: Annotated[\n",
        "        Dict[int, str],\n",
        "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
        "    ] = {},\n",
        ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
        "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
        "\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    sorted_inserts = sorted(inserts.items())\n",
        "\n",
        "    for line_number, text in sorted_inserts:\n",
        "        if 1 <= line_number <= len(lines) + 1:\n",
        "            lines.insert(line_number - 1, text + \"\\n\")\n",
        "        else:\n",
        "            return f\"Error: Line number {line_number} is out of range.\"\n",
        "\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.writelines(lines)\n",
        "\n",
        "    return f\"Document edited and saved to {file_name}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8yH1IAYK7nL"
      },
      "source": [
        "##### 🏗️ Activity #3:\n",
        "\n",
        "Describe, briefly, what each of these tools is doing in your own words.\n",
        "\n",
        "1. create_outline\n",
        "Purpose:\n",
        "Creates a numbered outline based on a list of points and saves it to a text file.\n",
        "\n",
        "Parameters:\n",
        "\n",
        "points: A list of strings representing main points or sections.\n",
        "\n",
        "file_name: Name of the file to save the outline.\n",
        "\n",
        "Returns:\n",
        "The file path where the outline is saved.\n",
        "\n",
        "2. read_document\n",
        "Purpose:\n",
        "Reads the content of a text document, optionally from a specific line range.\n",
        "\n",
        "Parameters:\n",
        "\n",
        "file_name: The name of the file to read.\n",
        "\n",
        "start: (Optional) Line number to start reading from.\n",
        "\n",
        "end: (Optional) Line number to stop reading at.\n",
        "\n",
        "Returns:\n",
        "A string containing the selected lines from the file.\n",
        "\n",
        "\n",
        "3. write_document\n",
        "Purpose:\n",
        "Writes a block of text to a file.\n",
        "\n",
        "Parameters:\n",
        "\n",
        "content: The text content to write.\n",
        "\n",
        "file_name: The name of the file to save to.\n",
        "\n",
        "Returns:\n",
        "The file path where the document is saved.\n",
        "\n",
        "4. edit_document\n",
        "Purpose:\n",
        "Inserts text at specific line numbers in an existing document.\n",
        "\n",
        "Parameters:\n",
        "\n",
        "file_name: The file to be edited.\n",
        "\n",
        "inserts: A dictionary where keys are 1-based line numbers and values are strings to insert at those lines.\n",
        "\n",
        "Returns:\n",
        "The file path where the edited document is saved, or an error message if a line number is out of range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Jw_XBIFwwa"
      },
      "source": [
        "### Document Writing State\n",
        "\n",
        "Just like with our Research Team state - we want to keep track of a few things, however this time - we also want to keep track of which files we've created - so let's add that here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "DoU2YwJRu7wD"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from pathlib import Path\n",
        "\n",
        "class DocWritingState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    team_members: str\n",
        "    next: str\n",
        "    current_files: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p1kQShmGHCh"
      },
      "source": [
        "### Document Writing Prelude Function\n",
        "\n",
        "Since we have a working directory - we want to be clear about what our current working directory looks like - this helper function will allow us to do that cleanly!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "G79mUggQGLVq"
      },
      "outputs": [],
      "source": [
        "def prelude(state):\n",
        "    written_files = []\n",
        "    if not WORKING_DIRECTORY.exists():\n",
        "        WORKING_DIRECTORY.mkdir()\n",
        "    try:\n",
        "        written_files = [\n",
        "            f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.rglob(\"*\")\n",
        "        ]\n",
        "    except:\n",
        "        pass\n",
        "    if not written_files:\n",
        "        return {**state, \"current_files\": \"No files written.\"}\n",
        "    return {\n",
        "        **state,\n",
        "        \"current_files\": \"\\nBelow are files your team has written to the directory:\\n\"\n",
        "        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbSre9agT9Gb"
      },
      "source": [
        "### Document Writing Node Creation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "v7oso327T_wa"
      },
      "outputs": [],
      "source": [
        "doc_writer_agent = create_agent(\n",
        "    llm,\n",
        "    [write_document, edit_document, read_document],\n",
        "    (\"You are an expert writing technical LinkedIn posts.\\n\"\n",
        "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
        ")\n",
        "context_aware_doc_writer_agent = prelude | doc_writer_agent\n",
        "doc_writing_node = functools.partial(\n",
        "    agent_node, agent=context_aware_doc_writer_agent, name=\"DocWriter\"\n",
        ")\n",
        "\n",
        "note_taking_agent = create_agent(\n",
        "    llm,\n",
        "    [create_outline, read_document],\n",
        "    (\"You are an expert senior researcher tasked with writing a LinkedIn post outline and\"\n",
        "    \" taking notes to craft a LinkedIn post.\\n{current_files}\"),\n",
        ")\n",
        "context_aware_note_taking_agent = prelude | note_taking_agent\n",
        "note_taking_node = functools.partial(\n",
        "    agent_node, agent=context_aware_note_taking_agent, name=\"NoteTaker\"\n",
        ")\n",
        "\n",
        "copy_editor_agent = create_agent(\n",
        "    llm,\n",
        "    [write_document, edit_document, read_document],\n",
        "    (\"You are an expert copy editor who focuses on fixing grammar, spelling, and tone issues\\n\"\n",
        "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
        ")\n",
        "context_aware_copy_editor_agent = prelude | copy_editor_agent\n",
        "copy_editing_node = functools.partial(\n",
        "    agent_node, agent=context_aware_copy_editor_agent, name=\"CopyEditor\"\n",
        ")\n",
        "\n",
        "dopeness_editor_agent = create_agent(\n",
        "    llm,\n",
        "    [write_document, edit_document, read_document],\n",
        "    (\"You are an expert in dopeness, litness, coolness, etc - you edit the document to make sure it's dope. Make sure to use a number of emojis.\"\n",
        "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
        ")\n",
        "context_aware_dopeness_editor_agent = prelude | dopeness_editor_agent\n",
        "dopeness_node = functools.partial(\n",
        "    agent_node, agent=context_aware_dopeness_editor_agent, name=\"DopenessEditor\"\n",
        ")\n",
        "\n",
        "doc_writing_supervisor = create_team_supervisor(\n",
        "    llm,\n",
        "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following workers: {team_members}. You should always verify the technical\"\n",
        "    \" contents after any edits are made. \"\n",
        "    \"Given the following user request,\"\n",
        "    \" respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. When each team is finished,\"\n",
        "    \" you must respond with FINISH.\"),\n",
        "    [\"DocWriter\", \"NoteTaker\", \"DopenessEditor\", \"CopyEditor\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUiNMpJBGXN0"
      },
      "source": [
        "### Document Writing Team LangGraph Construction\n",
        "\n",
        "This part is almost exactly the same (with a few extra nodes) as our Research Team LangGraph construction - so we'll leave it as one block!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Q6n8A1ytxVTv"
      },
      "outputs": [],
      "source": [
        "authoring_graph = StateGraph(DocWritingState)\n",
        "authoring_graph.add_node(\"DocWriter\", doc_writing_node)\n",
        "authoring_graph.add_node(\"NoteTaker\", note_taking_node)\n",
        "authoring_graph.add_node(\"CopyEditor\", copy_editing_node)\n",
        "authoring_graph.add_node(\"DopenessEditor\", dopeness_node)\n",
        "authoring_graph.add_node(\"supervisor\", doc_writing_supervisor)\n",
        "\n",
        "authoring_graph.add_edge(\"DocWriter\", \"supervisor\")\n",
        "authoring_graph.add_edge(\"NoteTaker\", \"supervisor\")\n",
        "authoring_graph.add_edge(\"CopyEditor\", \"supervisor\")\n",
        "authoring_graph.add_edge(\"DopenessEditor\", \"supervisor\")\n",
        "\n",
        "authoring_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\n",
        "        \"DocWriter\": \"DocWriter\",\n",
        "        \"NoteTaker\": \"NoteTaker\",\n",
        "        \"CopyEditor\" : \"CopyEditor\",\n",
        "        \"DopenessEditor\" : \"DopenessEditor\",\n",
        "        \"FINISH\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "authoring_graph.set_entry_point(\"supervisor\")\n",
        "compiled_authoring_graph = authoring_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx-EKGkHKUBO"
      },
      "source": [
        "#### Display Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "AZdOb3GZKSM7",
        "outputId": "6b64588d-5568-4234-d062-4dc83ea9abec"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        compiled_authoring_graph.get_graph().draw_mermaid_png(\n",
        "        #     curve_style=CurveStyle.LINEAR,\n",
        "        #     node_colors=NodeStyles(first=\"#ffdfba\", last=\"#baffc9\", default=\"#fad7de\"),\n",
        "        #     wrap_label_n_words=9,\n",
        "        #     output_file_path=None,\n",
        "        #     draw_method=MermaidDrawMethod.PYPPETEER,\n",
        "        #     background_color=\"white\",\n",
        "        #     padding=10,\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'DocWriter': StateNodeSpec(runnable=DocWriter(recurse=True), metadata=None, input=<class '__main__.DocWritingState'>, retry_policy=None),\n",
              " 'NoteTaker': StateNodeSpec(runnable=NoteTaker(recurse=True), metadata=None, input=<class '__main__.DocWritingState'>, retry_policy=None),\n",
              " 'CopyEditor': StateNodeSpec(runnable=CopyEditor(recurse=True), metadata=None, input=<class '__main__.DocWritingState'>, retry_policy=None),\n",
              " 'DopenessEditor': StateNodeSpec(runnable=DopenessEditor(recurse=True), metadata=None, input=<class '__main__.DocWritingState'>, retry_policy=None),\n",
              " 'supervisor': StateNodeSpec(runnable=ChatPromptTemplate(input_variables=['messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'options': \"['FINISH', 'DocWriter', 'NoteTaker', 'DopenessEditor', 'CopyEditor']\", 'team_members': 'DocWriter, NoteTaker, DopenessEditor, CopyEditor'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['team_members'], template='You are a supervisor tasked with managing a conversation between the following workers: {team_members}. You should always verify the technical contents after any edits are made. Given the following user request, respond with the worker to act next. Each worker will perform a task and respond with their results and status. When each team is finished, you must respond with FINISH.')), MessagesPlaceholder(variable_name='messages'), SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['options'], template='Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}'))])\n",
              " | RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fce91682110>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fce6c2e6f50>, root_client=<openai.OpenAI object at 0x7fce6cd7c510>, root_async_client=<openai.AsyncOpenAI object at 0x7fce6c2a3150>, model_name='gpt-4o-mini', openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'functions': [{'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'DocWriter', 'NoteTaker', 'DopenessEditor', 'CopyEditor']}]}}, 'required': ['next']}}], 'function_call': {'name': 'route'}})\n",
              " | JsonOutputFunctionsParser(), metadata=None, input=<class '__main__.DocWritingState'>, retry_policy=None)}"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "authoring_graph.nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['DocWriter', 'NoteTaker', 'CopyEditor', 'DopenessEditor', 'supervisor']"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[*authoring_graph.nodes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'DocWriter, NoteTaker, CopyEditor, DopenessEditor, supervisor'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\", \".join([*authoring_graph.nodes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB_rOw1hGpwd"
      },
      "source": [
        "Just as before - we'll need to create an \"interface\" between the level above, and our graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "G-RbbCKoG_nt"
      },
      "outputs": [],
      "source": [
        "def enter_chain(message: str):#, members: List[str]):\n",
        "    results = {\n",
        "        \"messages\": [HumanMessage(content=message)],\n",
        "        # \"team_members\": \", \".join(members),\n",
        "    }\n",
        "    return results\n",
        "\n",
        "authoring_chain = (\n",
        "    # functools.partial(enter_chain, members=authoring_graph.nodes)\n",
        "    enter_chain\n",
        "    | authoring_graph.compile()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgyhpTrRNgQd"
      },
      "source": [
        "Now we can test this out!\n",
        "\n",
        "> NOTE: It is possible you may see an error here - rerun the cell to clear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWUxv4XDx3kg",
        "outputId": "62ee7d3d-31ba-4348-b852-7fd96f6875ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'DocWriter'}}\n",
            "---\n",
            "{'DocWriter': {'messages': [HumanMessage(content='I have created and saved an outline for a LinkedIn post on Linear Regression. You can find it in the file named \"linear_regression_outline.txt\".', name='DocWriter')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'NoteTaker'}}\n",
            "---\n",
            "{'NoteTaker': {'messages': [HumanMessage(content='I have created and saved an outline for a LinkedIn post on Linear Regression. You can find it in the file named \"linear_regression_outline.txt\".', name='NoteTaker')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'DopenessEditor'}}\n",
            "---\n",
            "{'DopenessEditor': {'messages': [HumanMessage(content='I\\'ve created a dope outline for a LinkedIn post on Linear Regression and saved it in \"linear_regression_outline.txt\". It\\'s packed with insights and ready to shine! 🌟📊 Check it out!', name='DopenessEditor')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'CopyEditor'}}\n",
            "---\n",
            "{'CopyEditor': {'messages': [HumanMessage(content='I have created and saved an outline for a LinkedIn post on Linear Regression. You can find it in the file named \"linear_regression_outline.txt\".', name='CopyEditor')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'FINISH'}}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for s in authoring_chain.stream(\n",
        "    \"Write an outline for a short LinkedIn post on Linear Regression and write it to disk.\",\n",
        "    {\"recursion_limit\": 100},\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpW2R9SUHGUq"
      },
      "source": [
        "## Task 5: Meta-Supervisor and Full Graph\n",
        "\n",
        "Finally, now that we have our two LangGraph agents (some of which are already multi-agent), we can build a supervisor that sits above all of them!\n",
        "\n",
        "The final process, surprisingly, is quite straight forward!\n",
        "\n",
        "Let's jump in!\n",
        "\n",
        "First off - we'll need to create our supervisor agent node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "wkpxeUf9ygKp"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "supervisor_node = create_team_supervisor(\n",
        "    llm,\n",
        "    \"You are a Meta-supervisor tasked with managing a conversation between the\"\n",
        "    \" following teams: {team_members}. Given the following user request,\"\n",
        "    \" respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. When all workers are finished,\"\n",
        "    \" you must respond with FINISH.\",\n",
        "    [\"Research team\", \"LinkedIn team\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUvOh_xWIKig"
      },
      "source": [
        "We'll also create our new state - as well as some methods to help us navigate the new state and the subgraphs.\n",
        "\n",
        "> NOTE: We only pass the most recent message from the parent graph to the subgraph, and we only extract the most recent message from the subgraph to include in the state of the parent graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "O7HJ8MF0yh_i"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    next: str\n",
        "\n",
        "def get_last_message(state: State) -> str:\n",
        "    return state[\"messages\"][-1].content\n",
        "\n",
        "def join_graph(response: dict):\n",
        "    return {\"messages\": [response[\"messages\"][-1]]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5RHao1sIanG"
      },
      "source": [
        "Next, we'll create our base graph.\n",
        "\n",
        "Notice how each node we're adding is *AN ENTIRE LANGGRAPH AGENT* (wrapped into an LCEL chain with our helper functions above)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "PfCWABCMIaFy"
      },
      "outputs": [],
      "source": [
        "super_graph = StateGraph(State)\n",
        "\n",
        "super_graph.add_node(\"Research team\", get_last_message | research_chain | join_graph)\n",
        "super_graph.add_node(\n",
        "    \"LinkedIn team\", get_last_message | authoring_chain | join_graph\n",
        ")\n",
        "super_graph.add_node(\"Meta-supervisor\", supervisor_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpwpUXMtI62E"
      },
      "source": [
        "Next, we'll create our edges!\n",
        "\n",
        "This process is completely idenctical to what we've seen before - just addressing the LangGraph subgraph nodes instead of individual nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "tLtjRuUYI-fx"
      },
      "outputs": [],
      "source": [
        "super_graph.add_edge(\"Research team\", \"Meta-supervisor\")\n",
        "super_graph.add_edge(\"LinkedIn team\", \"Meta-supervisor\")\n",
        "super_graph.add_conditional_edges(\n",
        "    \"Meta-supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\n",
        "        \"LinkedIn team\": \"LinkedIn team\",\n",
        "        \"Research team\": \"Research team\",\n",
        "        \"FINISH\": END,\n",
        "    },\n",
        ")\n",
        "super_graph.set_entry_point(\"Meta-supervisor\")\n",
        "compiled_super_graph = super_graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(\n",
        "    Image(\n",
        "        compiled_super_graph.get_graph().draw_mermaid_png(\n",
        "               )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1KMfFqgJKw8"
      },
      "source": [
        "That's it!\n",
        "\n",
        "Now we can finally use our full agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M6wUDR-yk8s",
        "outputId": "056fe89e-5a81-4852-f0cb-35367da8cef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Meta-supervisor': {'next': 'Research team'}}\n",
            "---\n",
            "{'Research team': {'messages': [HumanMessage(content='🚀 Exciting News in AI Research! 🚀\\n\\nI\\'m thrilled to share insights from the recently published paper titled \"Extending Llama-3’s Context Ten-Fold Overnight\" by Peitian Zhang and colleagues. This groundbreaking study introduces a novel approach to significantly enhance the context length capabilities of large language models (LLMs), specifically extending the Llama-3-8B-Instruct model\\'s context from 8K tokens to an incredible 80K tokens using a technique known as QLoRA fine-tuning.\\n\\nThe efficiency of the training process is noteworthy, taking only 8 hours on a single 8xA800 (80G) GPU machine. The researchers have demonstrated that this dramatic increase in context length not only improves performance across various evaluation tasks—such as NIHS, topic retrieval, and long-context language understanding—but also preserves the model\\'s original capabilities in handling short contexts.\\n\\nInterestingly, this extension was primarily achieved using 3.5K synthetic training samples generated by GPT-4, hinting at the potential for even greater context lengths with additional computational resources. This advancement opens up new possibilities for applications requiring extensive context, pushing the boundaries of what LLMs can achieve. Kudos to the entire research team for their remarkable work! 🙌\\n\\nFor those interested in diving deeper into the research, you can access the full paper here: [Extending Llama-3’s Context Ten-Fold Overnight](https://arxiv.org/abs/2404.19553).\\n\\n#AI #MachineLearning #NaturalLanguageProcessing #Research #Llama3 #Innovation #TechAdvancement\\n\\n---\\n\\nFeel free to share your thoughts or questions in the comments!', name='PaperInformationRetriever')]}}\n",
            "---\n",
            "{'Meta-supervisor': {'next': 'LinkedIn team'}}\n",
            "---\n",
            "{'LinkedIn team': {'messages': [HumanMessage(content=\"I have successfully enhanced both documents with the additional flair you've specified. They are now ready to inspire and engage your audience! If you need anything else, just let me know. 🎉🚀\", name='CopyEditor')]}}\n",
            "---\n",
            "{'Meta-supervisor': {'next': 'FINISH'}}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
        "\n",
        "for s in compiled_super_graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(\n",
        "                content=\"Write a LinkedIn post on the paper 'Extending Llama-3’s Context Ten-Fold Overnight'. First consult the research team. Then make sure you consult the LinkedIn team, and check for copy editing and dopeness, and write the file to disk.\"\n",
        "            )\n",
        "        ],\n",
        "    },\n",
        "    {\"recursion_limit\": 30},\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuZAvSlJJpPP"
      },
      "source": [
        "## SAMPLE POST!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOEMCrXTJaxW"
      },
      "source": [
        "🚀 Exciting News in AI Research! 🚀\n",
        "\n",
        "We're thrilled to share a groundbreaking achievement in the field of large language models (LLMs)! A recent study titled \"Extending Llama-3’s Context Ten-Fold Overnight\" has successfully expanded the context length of Llama-3 from 8K to a staggering 80K tokens using QLoRA fine-tuning. This enhancement was accomplished in just eight hours on a single 8xA800 (80G) GPU machine, demonstrating both efficiency and effectiveness in model training.\n",
        "\n",
        "🔍 This remarkable advancement not only improves Llama-3’s performance across various benchmarks such as NIHS, topic retrieval, and long-context language understanding, but also preserves the model's ability to generalize beyond its training contexts, handling up to 128K tokens. This capability makes it a formidable tool in processing extensive textual information, pushing the boundaries of what AI can achieve.\n",
        "\n",
        "📊 Evaluated on LongBench and InfiniteBench, the model consistently outperformed baselines, setting a new standard in the field. Although it faced challenges in code completion tasks, the overall results are overwhelmingly positive.\n",
        "\n",
        "🌐 The full resources, including the model, training data, and code, are now publicly available, providing an invaluable asset for further research in training long-context LLMs.\n",
        "\n",
        "🔗 For more details, check out the full paper [here](https://www.emergentmind.com/papers/2404.19553).\n",
        "\n",
        "Let's continue pushing the limits of what AI can do! #AILLMs #MachineLearning #AIResearch #LanguageModels #Innovation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the reslut:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🚀 Exciting News in AI Research! 🚀\n",
        "\n",
        "I'm thrilled to share insights from the recently published paper titled \"Extending Llama-3’s Context Ten-Fold Overnight\" by Peitian Zhang and colleagues. This groundbreaking study introduces a novel approach to significantly enhance the context length capabilities of large language models (LLMs), specifically extending the Llama-3-8B-Instruct model's context from 8K tokens to an incredible 80K tokens using a technique known as QLoRA fine-tuning.\n",
        "\n",
        "The efficiency of the training process is noteworthy, taking only 8 hours on a single 8xA800 (80G) GPU machine. The researchers have demonstrated that this dramatic increase in context length not only improves performance across various evaluation tasks—such as NIHS, topic retrieval, and long-context language understanding—but also preserves the model's original capabilities in handling short contexts.\n",
        "\n",
        "Interestingly, this extension was primarily achieved using 3.5K synthetic training samples generated by GPT-4, hinting at the potential for even greater context lengths with additional computational resources. This advancement opens up new possibilities for applications requiring extensive context, pushing the boundaries of what LLMs can achieve. Kudos to the entire research team for their remarkable work! 🙌\n",
        "\n",
        "For those interested in diving deeper into the research, you can access the full paper here: [Extending Llama-3’s Context Ten-Fold Overnight](https://arxiv.org/abs/2404.19553).\n",
        "\n",
        "#AI #MachineLearning #NaturalLanguageProcessing #Research #Llama3 #Innovation #TechAdvancement\n",
        "\n",
        "---\n",
        "\n",
        "Feel free to share your thoughts or questions in the comments!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
